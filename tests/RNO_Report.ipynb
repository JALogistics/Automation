{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of the data:\n",
      "  DestinationWarehouse Factory Related transaction company  \\\n",
      "0      Rotterdam- KNNL      东台               JA Solar GmbH   \n",
      "1        Koper- Glovis      奉贤               JA Solar GmbH   \n",
      "2        Koper- Glovis      奉贤               JA Solar GmbH   \n",
      "3        Koper- Glovis      奉贤               JA Solar GmbH   \n",
      "4        Koper- Glovis      奉贤               JA Solar GmbH   \n",
      "\n",
      "  Related transaction Term        EXW        ETD        ETA update ETA  ATA  \\\n",
      "0                      CIF 2025-05-22 2025-05-27 2025-07-11 2025-07-14  NaN   \n",
      "1                      CIF 2025-05-27 2025-05-30 2025-07-14        NaT  NaN   \n",
      "2                      CIF 2025-05-27 2025-05-30 2025-07-14        NaT  NaN   \n",
      "3                      CIF 2025-05-27 2025-05-30 2025-07-14        NaT  NaN   \n",
      "4                      CIF 2025-05-27 2025-05-30 2025-07-14        NaT  NaN   \n",
      "\n",
      "  Date inbound  ...           Type.2 Auxiliary column  SKU  LRF Inv&type 是否签收  \\\n",
      "0          NaT  ...  JAM66D45-620/LB            D45LB  NaN  NaN      NaN  NaN   \n",
      "1          NaT  ...  JAM54D40-455/LB            D40LB  NaN  NaN      NaN  NaN   \n",
      "2          NaT  ...  JAM54D40-455/LB            D40LB  NaN  NaN      NaN  NaN   \n",
      "3          NaT  ...  JAM54D40-455/LB            D40LB  NaN  NaN      NaN  NaN   \n",
      "4          NaT  ...  JAM54D40-455/LB            D40LB  NaN  NaN      NaN  NaN   \n",
      "\n",
      "    型号 Unnamed: 67 Unnamed: 68  Unnamed: 69  \n",
      "0  NaN         NaN         NaN          NaN  \n",
      "1  NaN         NaN         NaN          NaN  \n",
      "2  NaN         NaN         NaN          NaN  \n",
      "3  NaN         NaN         NaN          NaN  \n",
      "4  NaN         NaN         NaN          NaN  \n",
      "\n",
      "[5 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "#Let connect to the database and print the data from this folder \n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "file_path = r\"C:\\Users\\DeepakSureshNidagund\\OneDrive - JA Solar GmbH\\Documents - Sales Dashboards (BI Solution)\\Y_EU Report\\Europe Stock 最新版.xlsx\"\n",
    "    \n",
    "try:\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(file_path):\n",
    "         raise FileNotFoundError(f\"Excel file not found at: {file_path}\")\n",
    "        \n",
    "    # Read the Excel file\n",
    "    df = pd.read_excel(file_path, sheet_name=\"Summary-Europe\")\n",
    "        \n",
    "    # Print the first few rows of the data\n",
    "    print(\"\\nFirst 5 rows of the data:\")\n",
    "    print(df.head())\n",
    "        \n",
    "except Exception as e:\n",
    " print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DestinationWarehouse', 'Factory', 'Related transaction company',\n",
       "       'Related transaction Term', 'EXW', 'ETD', 'ETA', 'update ETA', 'ATA',\n",
       "       'Date inbound', 'inbound status', 'B/L', 'Vessel', 'Sold Date', 'DN',\n",
       "       'Inv.', 'Type', 'Type.1', 'Container', 'Qty(PC)', 'Qty(plts)',\n",
       "       'Power(W)', 'Power(w/pc)', 'Status', 'Customer', 'Salesman',\n",
       "       'Region info', 'Delivery Terms', 'InternalSalesContract',\n",
       "       'External sales contract', 'Currency', 'Inv No.', 'C2 --> C1 Date',\n",
       "       'Handover Date', 'Contractual Delivery Week', 'Country Code', '状态',\n",
       "       'Internal related price', 'Battery type', 'Border Color',\n",
       "       'Junction box', 'length', 'Voltage', '边框信息', 'Storage duration',\n",
       "       'Sold（Week）', 'Storage duration（days）', 'original WH',\n",
       "       'Warehouse after transfer', 'ITS', 'ITS-Remark', 'Identify Risk stock',\n",
       "       'ERP NO', 'ETD month', 'Sold month', 'outbound quantity',\n",
       "       'Rest quantity', 'Released on the sea', 'Booking No.', 'EWX Week',\n",
       "       'Type.2', 'Auxiliary column', 'SKU', 'LRF', 'Inv&type', '是否签收', '型号',\n",
       "       'Unnamed: 67', 'Unnamed: 68', 'Unnamed: 69'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DestinationWarehouse', 'EXW', 'ETD', 'ETA', 'update ETA', 'ATA',\n",
       "       'Date inbound', 'inbound status', 'B/L', 'Vessel', 'Sold Date',\n",
       "       'Release Number', 'Invoice Number', 'Type', 'Type.1',\n",
       "       'Container Number', 'Qty(PC)', 'Qty(plts)', 'Power(W)', 'Power(w/pc)',\n",
       "       'Status', 'Customer', 'Salesman', 'Region info', 'Delivery Terms',\n",
       "       'InternalSalesContract', 'External sales contract', '边框信息', 'ITS',\n",
       "       'ITS-Remark', 'Identify Risk stock', 'ERP NO', 'Released on the sea',\n",
       "       'SKU', 'LRF', 'Ref1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 1. Remove special characters from specified columns\n",
    "import re\n",
    "def remove_special_chars(val):\n",
    "    if pd.isnull(val):\n",
    "        return val\n",
    "    # Remove special characters and then strip leading/trailing spaces\n",
    "    return re.sub(r'[^A-Za-z0-9 ]+', '', str(val)).strip()\n",
    "\n",
    "columns_to_clean = ['Container', 'DN', 'Inv.']\n",
    "\n",
    "for col in columns_to_clean:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(remove_special_chars)\n",
    "\n",
    "# 2. Rename the columns\n",
    "df = df.rename(columns={\n",
    "    'Inv.': 'Invoice Number',\n",
    "    'Container': 'Container Number',\n",
    "    'DN': 'Release Number'\n",
    "})\n",
    "\n",
    "# 3. Remove specified columns\n",
    "columns_to_remove = [\n",
    "    'Factory', 'Related transaction company', 'Related transaction Term', 'Currency', 'Inv No.', 'C2 --> C1 Date',\n",
    "    'Handover Date', 'Contractual Delivery Week', 'Country Code', '状态', 'Internal related price', 'Battery type',\n",
    "    'Border Color', 'Junction box', 'length', 'Voltage', 'Storage duration', 'Sold（Week）', 'Storage duration（days）',\n",
    "    'original WH', 'Warehouse after transfer', 'ETD month', 'Sold month', 'outbound quantity', 'Rest quantity','是否为5.0组件技术(间隙贴膜)'\n",
    "    'Released on the sea', 'Booking No.', 'EWX Week', 'Type.2', 'Auxiliary column', '成品料号', 'Inv&type', '是否签收',\n",
    "    '型号', 'Unnamed: 65', 'Unnamed: 66', 'Unnamed: 67','Unnamed: 68', 'Unnamed: 69'\n",
    "]\n",
    "\n",
    "# Drop the specified columns\n",
    "df = df.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n",
    "# Create a new column 'Ref1' as concatenation of 'Release Number' and 'Container Number'\n",
    "if 'Release Number' in df.columns and 'Container Number' in df.columns:\n",
    "    df['Ref1'] = df['Release Number'].astype(str) + df['Container Number'].astype(str)\n",
    "else:\n",
    "    df['Ref1'] = None\n",
    "\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into two datasets based on 'Release Number' and 'Not Released'\n",
    "Released_data = df[(df['Release Number'].notna() & (df['Release Number'].astype(str).str.strip() != \"\")) & \n",
    "         (df['Sold Date'].notna() & (df['Sold Date'].astype(str).str.strip() != \"\"))]\n",
    "\n",
    "\n",
    "Not_Released_data = df[(df['Release Number'].isna() | (df['Release Number'].astype(str).str.strip() == \"\")) & \n",
    "         (df['Sold Date'].isna() | (df['Sold Date'].astype(str).str.strip() == \"\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using latest report: CDR_2025-05-26.csv\n",
      "Full path: C:\\Users\\DeepakSureshNidagund\\OneDrive - JA Solar GmbH\\Logistics Reporting\\000_Master_Query_Reports\\Automation_DB\\CDR_Reports\\CDR_2025-05-26.csv\n",
      "\n",
      "First 3 rows of the data:\n",
      "  DestinationWarehouse        EXW        ETD        ETA update ETA  ATA  \\\n",
      "0      Rotterdam- KNNL 2025-05-22 2025-05-27 2025-07-11 2025-07-14  NaN   \n",
      "1        Koper- Glovis 2025-05-27 2025-05-30 2025-07-14        NaT  NaN   \n",
      "2        Koper- Glovis 2025-05-27 2025-05-30 2025-07-14        NaT  NaN   \n",
      "\n",
      "  Date inbound inbound status               B/L           Vessel  ...  \\\n",
      "0          NaT            NaN   177SNGNGN89779A  HMM SOUTHAMPTON  ...   \n",
      "1          NaT            NaN  HLCUSHA2412GOQB8              NaN  ...   \n",
      "2          NaT            NaN  HLCUSHA2412GOQB8              NaN  ...   \n",
      "\n",
      "  External sales contract       边框信息  ITS ITS-Remark Identify Risk stock  \\\n",
      "0                     NaN        NaN  NaN        NaN         all regular   \n",
      "1                     NaN  1762*1134  NaN        NaN         all regular   \n",
      "2                     NaN  1762*1134  NaN        NaN         all regular   \n",
      "\n",
      "       ERP NO  Released on the sea  SKU  LRF            Ref1  \n",
      "0  3830802207                  NaN  NaN  NaN  nanFDCU0058487  \n",
      "1  6105004268                  NaN  NaN  NaN  nanHLBU1917724  \n",
      "2  6105004268                  NaN  NaN  NaN  nanHAMU3953218  \n",
      "\n",
      "[3 rows x 36 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DeepakSureshNidagund\\AppData\\Local\\Temp\\ipykernel_21960\\3892510382.py:49: DtypeWarning: Columns (12,23,27,28,29,30,31,34,35,36,62,63,64,65,66,67,69,70) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cdr = pd.read_csv(latest_file)\n"
     ]
    }
   ],
   "source": [
    "# Get the latest CDR report\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Directory path\n",
    "reports_dir = r\"C:\\Users\\DeepakSureshNidagund\\OneDrive - JA Solar GmbH\\Logistics Reporting\\000_Master_Query_Reports\\Automation_DB\\CDR_Reports\"\n",
    "\n",
    "# Check if directory exists\n",
    "if not os.path.exists(reports_dir):\n",
    "    print(f\"Directory does not exist: {reports_dir}\")\n",
    "    print(\"Creating directory...\")\n",
    "    os.makedirs(reports_dir, exist_ok=True)\n",
    "\n",
    "# Try different patterns to find CDR reports\n",
    "patterns = [\n",
    "    \"CDR_*.csv\",  # Primary pattern\n",
    "    \"*CDR*.csv\",  # Secondary pattern - any file with CDR in the name\n",
    "    \"*.csv\"       # Fallback pattern - any CSV file\n",
    "]\n",
    "\n",
    "report_files = []\n",
    "for pattern in patterns:\n",
    "    full_pattern = os.path.join(reports_dir, pattern)\n",
    "    found_files = glob.glob(full_pattern)\n",
    "    if found_files:\n",
    "        report_files = found_files\n",
    "        break\n",
    "\n",
    "if not report_files:\n",
    "    print(f\"No CSV files found in {reports_dir}\")\n",
    "else:\n",
    "    try:\n",
    "        # Try to get the latest file based on date in filename\n",
    "        latest_file = max(report_files, key=lambda x: \n",
    "                        datetime.datetime.strptime(os.path.basename(x).split('_')[1].split('.')[0], \n",
    "                                                \"%Y-%m-%d\"))\n",
    "    except (IndexError, ValueError):\n",
    "        print(\"Could not parse dates from filenames, using file modification time instead.\")\n",
    "        latest_file = max(report_files, key=os.path.getmtime)\n",
    "\n",
    "    print(f\"\\nUsing latest report: {os.path.basename(latest_file)}\")\n",
    "    print(f\"Full path: {latest_file}\")\n",
    "\n",
    "    try:\n",
    "        # Read the CSV file and print first 3 rows\n",
    "        cdr = pd.read_csv(latest_file)\n",
    "        print(\"\\nFirst 3 rows of the data:\")\n",
    "        print(df.head(3))\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {latest_file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now Combinr the 'Released_data' with CDR data to remove the Outbound data from the Released_data based on Ref1\n",
    "\n",
    "cdr_columns = [\"Ref1\", \"Current_Status\", \"Outbound date\", \"Agreed Delivery date\", \"Delivery date\", \"Delivery_Status\"]\n",
    "cdr_selected = cdr[cdr_columns]\n",
    "\n",
    "# Merge the main dataframe with CDR data using Ref1 as the key\n",
    "rno = pd.merge(\n",
    "    Released_data,\n",
    "    cdr_selected,\n",
    "    on=\"Ref1\",\n",
    "    how=\"left\"  # Using left join to keep all records from main df\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DestinationWarehouse', 'EXW', 'ETD', 'ETA', 'update ETA', 'ATA',\n",
      "       'Date inbound', 'inbound status', 'B/L', 'Vessel', 'Sold Date',\n",
      "       'Release Number', 'Invoice Number', 'Type', 'Type.1',\n",
      "       'Container Number', 'Qty(PC)', 'Qty(plts)', 'Power(W)', 'Power(w/pc)',\n",
      "       'Status', 'Customer', 'Salesman', 'Region info', 'Delivery Terms',\n",
      "       'InternalSalesContract', 'External sales contract', '边框信息', 'ITS',\n",
      "       'ITS-Remark', 'Identify Risk stock', 'ERP NO', 'Released on the sea',\n",
      "       'SKU', 'LRF', 'Ref1', 'Current_Status', 'Outbound date',\n",
      "       'Agreed Delivery date', 'Delivery date', 'Delivery_Status'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(rno.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the Outbound Pcs from CDR again with summarization by Ref1 and add a new column called Outbound_Pcs_CDR\n",
    "cdr['Piece'] = pd.to_numeric(cdr['Piece'], errors='coerce')\n",
    "\n",
    "# Create separate summaries for each status\n",
    "on_sea_summary = cdr[cdr['Current_Status'] == 'On Sea'].groupby('Ref1')['Piece'].sum().reset_index()\n",
    "on_sea_summary = on_sea_summary.rename(columns={'Piece': 'On_Sea_Pcs'})\n",
    "\n",
    "in_stock_summary = cdr[cdr['Current_Status'] == 'In-Stock'].groupby('Ref1')['Piece'].sum().reset_index()\n",
    "in_stock_summary = in_stock_summary.rename(columns={'Piece': 'In_Stock_Pcs'})\n",
    "\n",
    "outbounded_summary = cdr[cdr['Current_Status'] == 'Outbounded'].groupby('Ref1')['Piece'].sum().reset_index()\n",
    "outbounded_summary = outbounded_summary.rename(columns={'Piece': 'Outbounded_Pcs'})\n",
    "\n",
    "# Merge all summaries with the main dataframe\n",
    "rno = pd.merge(\n",
    "    rno,\n",
    "    on_sea_summary,\n",
    "    on=\"Ref1\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "rno = pd.merge(\n",
    "    rno,\n",
    "    in_stock_summary,\n",
    "    on=\"Ref1\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "rno = pd.merge(\n",
    "    rno,\n",
    "    outbounded_summary,\n",
    "    on=\"Ref1\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Fill NaN values with 0 for all new columns\n",
    "rno['On_Sea_Pcs'] = rno['On_Sea_Pcs'].fillna(0)\n",
    "rno['In_Stock_Pcs'] = rno['In_Stock_Pcs'].fillna(0)\n",
    "rno['Outbounded_Pcs'] = rno['Outbounded_Pcs'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column, Outbound_Pcs_CDR compare which is Outbound_Pcs = Qty(PC) in rno report\n",
    "rno['Qty(PC)'] = pd.to_numeric(rno['Qty(PC)'], errors='coerce')\n",
    "rno['Outbounded_Pcs'] = pd.to_numeric(rno['Outbounded_Pcs'], errors='coerce')\n",
    "\n",
    "# Create comparison column based on Current_Status\n",
    "import numpy as np\n",
    "rno['Outbound_Comparison'] = np.where(\n",
    "    rno['Current_Status'] == 'Outbounded',\n",
    "    rno['Outbounded_Pcs'] - rno['Qty(PC)'],\n",
    "    rno['Qty(PC)']\n",
    ")\n",
    "\n",
    "#replace the neqtive value of 'Outbound_Comparison' with  rno['Qty(PC)']\n",
    "rno['Outbound_Comparison'] = np.where(\n",
    "    rno['Outbound_Comparison'] < 0,\n",
    "    rno['Qty(PC)'],\n",
    "    rno['Outbound_Comparison']\n",
    ")\n",
    "\n",
    "# Add a new column as Case1 which is ['Outbound_Comparison'] == ['Qty(PC)'] as True and False\n",
    "rno['Case1'] = np.where(\n",
    "    rno['Outbound_Comparison'] == rno['Qty(PC)'],\n",
    "    True,\n",
    "    False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found latest WMS report: Combined_Outbound_WMS_20250522.xlsx\n",
      "Full path: C:\\Users\\DeepakSureshNidagund\\OneDrive - JA Solar GmbH\\Documents - Sales Dashboards (BI Solution)\\a_Combinded WM_Report\\Outbound_WMS_Report\\Combined_Outbound_WMS_20250522.xlsx\n",
      "Last modified: 2025-05-22 19:16:57.520339\n",
      "\n",
      "Successfully loaded data with 23954 rows and 26 columns\n",
      "Index(['Base name', 'Organization Code', 'Organization Name', 'Warehouse',\n",
      "       'Wharea', 'Wharea Name', 'Wharea.1', 'Internal invoice number',\n",
      "       'Container number', 'Release number', 'Type', 'Quantity', 'Wattage',\n",
      "       'Total wattage', 'Trade terms', 'Operation Time', 'statisticsDate',\n",
      "       'Outbound time', 'Signing time', 'External contract number',\n",
      "       'Delivery Address', 'Country Code', 'Number of Pallets',\n",
      "       'carbonFootprint', 'Source_File', 'Ref1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Get data from WMS Report\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "#Define the directory path for WMS reports\n",
    "wms_dir = r\"C:\\Users\\DeepakSureshNidagund\\OneDrive - JA Solar GmbH\\Documents - Sales Dashboards (BI Solution)\\a_Combinded WM_Report\\Outbound_WMS_Report\"\n",
    "\n",
    "# Check if directory exists\n",
    "if not os.path.exists(wms_dir):\n",
    "    print(f\"Error: Directory does not exist: {wms_dir}\")\n",
    "    exit(1)\n",
    "\n",
    "# Find all Excel files in the directory\n",
    "excel_files = glob.glob(os.path.join(wms_dir, \"*.xlsx\"))\n",
    "\n",
    "# Check if any files were found\n",
    "if not excel_files:\n",
    "    print(f\"No Excel files found in {wms_dir}\")\n",
    "    exit(1)\n",
    "\n",
    "# Get the latest file based on modification time\n",
    "latest_file = max(excel_files, key=os.path.getmtime)\n",
    "\n",
    "print(f\"Found latest WMS report: {os.path.basename(latest_file)}\")\n",
    "print(f\"Full path: {latest_file}\")\n",
    "print(f\"Last modified: {datetime.fromtimestamp(os.path.getmtime(latest_file))}\")\n",
    "\n",
    "try:\n",
    "    # Read the Excel file\n",
    "    wms_Outbound = pd.read_excel(latest_file)\n",
    "    print(f\"\\nSuccessfully loaded data with {len( wms_Outbound)} rows and {len( wms_Outbound.columns)} columns\")\n",
    "    \n",
    "    \n",
    "    print( wms_Outbound.columns)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error reading file {latest_file}: {e}\") \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create Ref1 column as concatenation of Release Number and Container Number\n",
    "# if 'Release number' in wms_Outbound.columns and 'Container number' in wms_Outbound.columns:\n",
    "#     wms_Outbound['Ref1'] = wms_Outbound['Release number'].astype(str) + wms_Outbound['Container number'].astype(str)\n",
    "# else:\n",
    "#     wms_Outbound['Ref1'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on Ref1 from rno and Ref1 from wms_Outbound, get the total 'Quantity' from wms_Outbound and add it to rno as a new column called 'Outbound_Pcs_WMS'\n",
    "wms_summary = wms_Outbound.groupby('Ref1')['Quantity'].sum().reset_index()\n",
    "wms_summary = wms_summary.rename(columns={'Quantity': 'Pcs_from_wms'})\n",
    "\n",
    "# Merge the summary with rno DataFrame\n",
    "rno = pd.merge(\n",
    "    rno,\n",
    "    wms_summary,\n",
    "    on='Ref1',\n",
    "    how='left'  # Use left join to keep all records from rno\n",
    ")\n",
    "\n",
    "\n",
    "# Fill any NaN values with 0 for the new column\n",
    "rno['Pcs_from_wms'] = rno['Pcs_from_wms'].fillna(0)\n",
    "\n",
    "# Convert to numeric to ensure proper data type\n",
    "rno['Pcs_from_wms'] = pd.to_numeric(rno['Pcs_from_wms'], errors='coerce')\n",
    "\n",
    "# Add a new column as Case2 which is rno['Pcs_from_wms'] == rno['Outbounded_Pcs'] as True and False\n",
    "rno['Case2'] = np.where(\n",
    "    rno['Pcs_from_wms'] == rno['Outbounded_Pcs'],\n",
    "    True,\n",
    "    False\n",
    ")\n",
    "\n",
    "\n",
    "# Add a new column as Case3 which is ['Outbound_Comparison'] == ['Qty(PC)'] as True and False\n",
    "rno['Case3'] = np.where(\n",
    "    rno['Pcs_from_wms'] == rno['Qty(PC)'] ,\n",
    "    True,\n",
    "    False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get two summaries from CDR:\n",
    "# 1. Total pieces by container\n",
    "# 2. Outbounded pieces by container\n",
    "cdr_total_summary = cdr.groupby('Container No.')['Piece'].sum().reset_index()\n",
    "cdr_outbound_summary = cdr[cdr['Current_Status'] == 'Outbounded'].groupby('Container No.')['Piece'].sum().reset_index()\n",
    "\n",
    "# Rename columns to be descriptive\n",
    "cdr_total_summary = cdr_total_summary.rename(columns={'Piece': 'cnt_Total_Pcs_cdr'})\n",
    "cdr_outbound_summary = cdr_outbound_summary.rename(columns={'Piece': 'cnt_Outbound_Pcs_cdr'})\n",
    "\n",
    "# Merge both summaries with rno DataFrame\n",
    "rno = pd.merge(\n",
    "    rno,\n",
    "    cdr_total_summary,\n",
    "    left_on='Container Number',\n",
    "    right_on='Container No.',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "rno = pd.merge(\n",
    "    rno,\n",
    "    cdr_outbound_summary,\n",
    "    left_on='Container Number',\n",
    "    right_on='Container No.',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN values with 0 for both new columns\n",
    "rno['cnt_Total_Pcs_cdr'] = rno['cnt_Total_Pcs_cdr'].fillna(0)\n",
    "rno['cnt_Outbound_Pcs_cdr'] = rno['cnt_Outbound_Pcs_cdr'].fillna(0)\n",
    "\n",
    "# Convert to numeric to ensure proper data type\n",
    "rno['cnt_Total_Pcs_cdr'] = pd.to_numeric(rno['cnt_Total_Pcs_cdr'], errors='coerce')\n",
    "rno['cnt_Outbound_Pcs_cdr'] = pd.to_numeric(rno['cnt_Outbound_Pcs_cdr'], errors='coerce')\n",
    "\n",
    "# Clean up by dropping the extra 'Container No.' columns that were added during merges\n",
    "rno = rno.drop(['Container No._x', 'Container No._y'], axis=1, errors='ignore')\n",
    "\n",
    "rno['Case4'] = np.where(\n",
    "    rno['cnt_Outbound_Pcs_cdr'] == rno['Qty(PC)'],\n",
    "    True,\n",
    "    False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Add the filters one by one to row the filters\n",
    "\n",
    "# Now filter out rows that meet all the specified conditions where Currecnt status = Outbounded  & In stock = 0  & Case_2 = True (cdr pcs = wms pcs only outbound )\n",
    "rno = rno[~((rno['Current_Status'] == 'Outbounded') & \n",
    "            (rno['In_Stock_Pcs'] == 0) & \n",
    "            (rno['Case2'] == True))]\n",
    "\n",
    "\n",
    "# Now filter out rows that meet all the specified conditions where Currecnt status = Outbounded  & In stock = 0  & Case_3 = True (wms pcs = wms pcs only outbound )\n",
    "rno = rno[~((rno['Current_Status'] == 'Outbounded') & \n",
    "            (rno['In_Stock_Pcs'] == 0) & \n",
    "            (rno['Case3'] == True))]\n",
    "\n",
    "\n",
    "\n",
    "# Now filter out rows that meet all the specified conditions where Currecnt status = Outbounded  & In stock = 0  & Case_4 = True (cdr pcs = rno pcs at cotainer lvl pcs only outbound )\n",
    "rno = rno[~((rno['Current_Status'] == 'Outbounded') & \n",
    "            (rno['In_Stock_Pcs'] == 0) & \n",
    "            (rno['Case4'] == True))]\n",
    "\n",
    "# Remove the row where the Current status == Outbounded and Outbound_Comparison ==0\n",
    "rno = rno[\n",
    "    ~((rno['Current_Status'] == 'Outbounded') & \n",
    "      (rno['Outbound_Comparison'] == 0))\n",
    "]\n",
    "\n",
    "\n",
    "# Now remove the row where the Current status == Outbounded and Case_2 == TRUE\n",
    "rno = rno[\n",
    "    ~((rno['Current_Status'] == 'Outbounded') & \n",
    "      (rno['Case2'] == True))\n",
    "]\n",
    "\n",
    "# Remove the rows Current status == Outbounded\n",
    "rno = rno[\n",
    "    ~((rno['Current_Status'] == 'Outbounded'))]\n",
    "\n",
    "\n",
    "# Remove rows where Container Number is null/blank\n",
    "rno = rno[rno['Container Number'].notna() & (rno['Container Number'].str.strip() != '')]\n",
    "\n",
    "\n",
    "# Read the Remove_data file\n",
    "remove_data_path = r\"C:\\Users\\DeepakSureshNidagund\\Downloads\\Reporting Application\\Automation\\automation\\tests\\Remove_data.xlsx\"\n",
    "remove_df = pd.read_excel(remove_data_path)\n",
    "ref1_to_remove = remove_df['Ref1'].tolist()\n",
    "rno = rno[~rno['Ref1'].isin(ref1_to_remove)]\n",
    "\n",
    "# Reorder columns to bring specified columns to front\n",
    "first_columns = ['Ref1', 'Container Number', 'Release Number']\n",
    "other_columns = [col for col in rno.columns if col not in first_columns]\n",
    "rno = rno[first_columns + other_columns]\n",
    "\n",
    "# change these columns to date format\n",
    "rno['Sold Date'] = pd.to_datetime(rno['Sold Date'])\n",
    "rno['Outbound date'] = pd.to_datetime(rno['Outbound date'])\n",
    "rno['Agreed Delivery date'] = pd.to_datetime(rno['Agreed Delivery date'])\n",
    "rno['Delivery date'] = pd.to_datetime(rno['Delivery date'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "\n",
    "# Define the file path\n",
    "excel_path = r\"C:\\Users\\DeepakSureshNidagund\\OneDrive - JA Solar GmbH\\Logistics Reporting\\000_Master_Query_Reports\\Automation_DB\\RNO_Report\\RNO_Report - Copy.xlsx\"\n",
    "\n",
    "# Load the existing workbook\n",
    "book = openpyxl.load_workbook(excel_path)\n",
    "\n",
    "# Select the sheet\n",
    "sheet = book['RNO Report']\n",
    "\n",
    "# Delete all rows except the header\n",
    "while sheet.max_row > 1:  # Keep the first row (header)\n",
    "    sheet.delete_rows(2)  # Always delete row 2 until only header remains\n",
    "\n",
    "# Save the workbook after clearing data\n",
    "book.save(excel_path)\n",
    "book.close()\n",
    "\n",
    "# Write the new data\n",
    "with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
    "    rno.to_excel(writer, sheet_name='RNO Report', index=False, header=False, startrow=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Released_data.to_csv(\"Released_data.csv\", index=False)\n",
    "# Not_Released_data.to_csv(\"Not_Released_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
