"""
CMR File Validation System
==========================
This script validates container names against pre-extracted CMR file data.
It uses the all_files_extracted.xlsx file to avoid re-scanning folders.

Author: Automated System
Date: 2026-01-26
Python Version: 3.8+
"""

import pandas as pd
import re
import logging
from datetime import datetime


# ============================================================================
# CONFIGURATION
# ============================================================================

CONFIG = {
    # Pre-extracted files Excel (generated by extract_all_files.py)
    "extracted_files_path": r"C:\Users\DeepakSureshNidagund\Downloads\Reporting Application\Automation\automation\all_files_extracted.xlsx",
    
    # Target Excel file containing container names to validate
    "target_excel_path": r"C:\Users\DeepakSureshNidagund\Downloads\Reporting Application\Automation\automation\tests\CMRs\check for CMRs.xlsx",
    
    # Column name in target Excel that contains container names
    "container_column": "Container Name",
    
    # Output validation report
    "output_report": "cmr_validation_report.xlsx",
}


# ============================================================================
# LOGGING SETUP
# ============================================================================

def setup_logging():
    """Configure logging for progress tracking."""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )


# ============================================================================
# UTILITY FUNCTIONS
# ============================================================================

def clean_filename(filename):
    """
    Clean special characters from filename for better matching.
    Removes: spaces, hyphens, underscores, dots, and other special chars.
    Keeps only alphanumeric characters.
    
    Args:
        filename (str): Original filename
        
    Returns:
        str: Cleaned filename (uppercase, alphanumeric only)
    """
    if pd.isna(filename):
        return ""
    
    # Convert to string and uppercase
    cleaned = str(filename).upper()
    
    # Remove all special characters, keep only alphanumeric
    cleaned = re.sub(r'[^A-Z0-9]', '', cleaned)
    
    return cleaned


def extract_filename_parts(filename):
    """
    Extract multiple parts from filename for matching.
    Handles cases like:
    - "2311160002- TRHU7369936" -> extracts "TRHU7369936"
    - "2505130072-EISU8486100-FCA-14-504" -> extracts "EISU8486100"
    
    Special handling for container number patterns (4 letters + 7 digits).
    
    Args:
        filename (str): Original filename
        
    Returns:
        list: List of cleaned filename parts for matching
    """
    if pd.isna(filename):
        return []
    
    # Convert to string and uppercase
    filename_str = str(filename).upper()
    
    cleaned_parts = []
    
    # METHOD 1: Extract container number patterns (4 letters + 7 digits)
    # Patterns like: TRHU7369936, EISU8486100, CMAU1234567
    container_pattern = r'[A-Z]{4}\d{7}'
    container_matches = re.findall(container_pattern, filename_str)
    for match in container_matches:
        if match not in cleaned_parts:
            cleaned_parts.append(match)
    
    # METHOD 2: Split by common separators and extract parts
    parts = re.split(r'[-_\s,]+', filename_str)
    
    for part in parts:
        cleaned = re.sub(r'[^A-Z0-9]', '', part)
        # Only include parts with at least 4 characters (to avoid noise)
        if len(cleaned) >= 4 and cleaned not in cleaned_parts:
            cleaned_parts.append(cleaned)
    
    # METHOD 3: Add the fully cleaned version (all parts combined)
    full_cleaned = re.sub(r'[^A-Z0-9]', '', filename_str)
    if full_cleaned and full_cleaned not in cleaned_parts:
        cleaned_parts.insert(0, full_cleaned)
    
    return cleaned_parts


# ============================================================================
# DATA LOADER CLASS
# ============================================================================

class DataLoader:
    """Loads and prepares data from Excel files."""
    
    @staticmethod
    def load_extracted_files(file_path):
        """
        Load pre-extracted files from Excel.
        
        Args:
            file_path (str): Path to all_files_extracted.xlsx
            
        Returns:
            pd.DataFrame: DataFrame with cleaned filenames
        """
        logging.info(f"Loading extracted files from: {file_path}")
        
        try:
            # Read the "Simple List" sheet (has File Name (no extension) and File Type)
            df = pd.read_excel(file_path, sheet_name="Simple List")
            
            logging.info(f"Loaded {len(df)} files from extracted data")
            
            # Create cleaned filename parts for matching
            df['Filename_Parts'] = df['File Name (no extension)'].apply(extract_filename_parts)
            
            # Remove any rows with empty parts
            df = df[df['Filename_Parts'].apply(len) > 0]
            
            logging.info(f"After cleaning: {len(df)} files ready for matching")
            
            return df
            
        except FileNotFoundError:
            logging.error(f"Extracted files not found: {file_path}")
            raise
        except Exception as e:
            logging.error(f"Error loading extracted files: {e}")
            raise
    
    @staticmethod
    def load_container_names(file_path, column_name):
        """
        Load container names from target Excel file.
        
        Args:
            file_path (str): Path to target Excel file
            column_name (str): Column containing container names
            
        Returns:
            pd.DataFrame: DataFrame with container names and cleaned versions
        """
        logging.info(f"Loading container names from: {file_path}")
        
        try:
            # Read target Excel file
            df = pd.read_excel(file_path)
            
            if df.empty:
                logging.warning("Target Excel file is empty")
                return pd.DataFrame()
            
            # Check if column exists
            if column_name not in df.columns:
                raise ValueError(
                    f"Column '{column_name}' not found in Excel. "
                    f"Available columns: {', '.join(df.columns)}"
                )
            
            # Extract container names
            containers = df[[column_name]].copy()
            containers = containers.dropna()
            containers = containers.drop_duplicates()
            
            # Create cleaned version for matching
            containers['Cleaned_Container'] = containers[column_name].apply(clean_filename)
            
            # Remove any empty cleaned containers
            containers = containers[containers['Cleaned_Container'] != '']
            
            logging.info(f"Loaded {len(containers)} unique container names")
            
            return containers
            
        except FileNotFoundError:
            logging.error(f"Target Excel file not found: {file_path}")
            raise
        except Exception as e:
            logging.error(f"Error loading container names: {e}")
            raise


# ============================================================================
# VALIDATOR CLASS
# ============================================================================

class CMRValidator:
    """Validates container names against extracted CMR files."""
    
    def __init__(self, extracted_files_df, container_names_df):
        """
        Initialize the validator.
        
        Args:
            extracted_files_df (pd.DataFrame): DataFrame with extracted files
            container_names_df (pd.DataFrame): DataFrame with container names
        """
        self.extracted_files_df = extracted_files_df
        self.container_names_df = container_names_df
        
        # Create lookup dictionary for faster matching
        # Key: cleaned filename part, Value: dict with file type and original name
        # Multiple parts from same file can map to same file info
        self.file_lookup = {}
        for _, row in extracted_files_df.iterrows():
            filename_parts = row['Filename_Parts']
            file_info = {
                'file_type': row['File Type'],
                'original_name': row['File Name (no extension)']
            }
            
            # Add each part as a lookup key
            for part in filename_parts:
                if part and part not in self.file_lookup:
                    self.file_lookup[part] = file_info
        
        logging.info(f"Created lookup index with {len(self.file_lookup)} searchable parts")
    
    def validate(self):
        """
        Validate all container names against extracted files.
        
        Returns:
            pd.DataFrame: Validation results
        """
        logging.info("Starting validation process...")
        
        validation_results = []
        
        for _, row in self.container_names_df.iterrows():
            original_container = row[CONFIG['container_column']]
            cleaned_container = row['Cleaned_Container']
            
            # Check if cleaned container name exists in file lookup
            if cleaned_container in self.file_lookup:
                file_info = self.file_lookup[cleaned_container]
                validation_results.append({
                    'Container Name': original_container,
                    'File Exists': 'Yes',
                    'File Type': file_info['file_type'],
                    'Matched File Name': file_info['original_name']
                })
            else:
                validation_results.append({
                    'Container Name': original_container,
                    'File Exists': 'No',
                    'File Type': 'N/A',
                    'Matched File Name': 'N/A'
                })
        
        df = pd.DataFrame(validation_results)
        
        logging.info("Validation complete")
        
        return df
    
    def generate_summary(self, validation_df):
        """
        Generate summary statistics.
        
        Args:
            validation_df (pd.DataFrame): Validation results
            
        Returns:
            pd.DataFrame: Summary statistics
        """
        total = len(validation_df)
        found = len(validation_df[validation_df['File Exists'] == 'Yes'])
        missing = total - found
        match_rate = (found / total * 100) if total > 0 else 0
        
        # Count by file type (for found files only)
        found_files = validation_df[validation_df['File Exists'] == 'Yes']
        pdf_count = len(found_files[found_files['File Type'] == 'PDF'])
        jpeg_count = len(found_files[found_files['File Type'] == 'JPEG'])
        
        summary_data = [
            {'Metric': 'Total Container Names', 'Value': total},
            {'Metric': 'Files Found', 'Value': found},
            {'Metric': 'Files Missing', 'Value': missing},
            {'Metric': 'Match Rate (%)', 'Value': f'{match_rate:.2f}%'},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Found - PDF Files', 'Value': pdf_count},
            {'Metric': 'Found - JPEG Files', 'Value': jpeg_count},
        ]
        
        summary_df = pd.DataFrame(summary_data)
        
        logging.info(f"Summary - Total: {total}, Found: {found}, Missing: {missing}, Match Rate: {match_rate:.2f}%")
        
        return summary_df
    
    def get_missing_containers(self, validation_df):
        """
        Get list of missing containers for detailed analysis.
        
        Args:
            validation_df (pd.DataFrame): Validation results
            
        Returns:
            pd.DataFrame: Missing containers only
        """
        missing_df = validation_df[validation_df['File Exists'] == 'No'].copy()
        missing_df = missing_df[['Container Name']].reset_index(drop=True)
        
        logging.info(f"Missing containers: {len(missing_df)}")
        
        return missing_df


# ============================================================================
# EXCEL EXPORTER CLASS
# ============================================================================

class ExcelExporter:
    """Exports validation results to Excel."""
    
    @staticmethod
    def export_validation_report(validation_df, summary_df, missing_df, output_path):
        """
        Export complete validation report with multiple sheets.
        
        Args:
            validation_df (pd.DataFrame): Validation results
            summary_df (pd.DataFrame): Summary statistics
            missing_df (pd.DataFrame): Missing containers list
            output_path (str): Path to output Excel file
        """
        logging.info(f"Exporting validation report to: {output_path}")
        
        try:
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                # Sheet 1: Validation Results
                validation_df.to_excel(
                    writer, 
                    index=False, 
                    sheet_name='Validation Results'
                )
                
                # Sheet 2: Summary Statistics
                summary_df.to_excel(
                    writer, 
                    index=False, 
                    sheet_name='Summary'
                )
                
                # Sheet 3: Missing Containers Only
                if not missing_df.empty:
                    missing_df.to_excel(
                        writer, 
                        index=False, 
                        sheet_name='Missing Containers'
                    )
            
            logging.info(f"Successfully exported validation report")
            logging.info(f"Report contains {len(validation_df)} validation records")
            
        except Exception as e:
            logging.error(f"Error exporting validation report: {e}")
            raise


# ============================================================================
# MAIN APPLICATION CLASS
# ============================================================================

class CMRValidationApp:
    """Main application orchestrator."""
    
    def __init__(self, config):
        """
        Initialize the application.
        
        Args:
            config (dict): Configuration dictionary
        """
        self.config = config
        self.data_loader = DataLoader()
        self.validator = None
        self.exporter = ExcelExporter()
    
    def run(self):
        """Execute the complete validation workflow."""
        try:
            logging.info("=" * 70)
            logging.info("CMR VALIDATION SYSTEM - STARTING")
            logging.info("=" * 70)
            logging.info("")
            
            # Step 1: Load extracted files
            extracted_files_df = self.data_loader.load_extracted_files(
                self.config['extracted_files_path']
            )
            logging.info("")
            
            # Step 2: Load container names
            container_names_df = self.data_loader.load_container_names(
                self.config['target_excel_path'],
                self.config['container_column']
            )
            logging.info("")
            
            # Step 3: Initialize validator and validate
            self.validator = CMRValidator(extracted_files_df, container_names_df)
            validation_df = self.validator.validate()
            logging.info("")
            
            # Step 4: Generate summary and missing list
            summary_df = self.validator.generate_summary(validation_df)
            missing_df = self.validator.get_missing_containers(validation_df)
            logging.info("")
            
            # Step 5: Export results
            self.exporter.export_validation_report(
                validation_df,
                summary_df,
                missing_df,
                self.config['output_report']
            )
            logging.info("")
            
            logging.info("=" * 70)
            logging.info("CMR VALIDATION SYSTEM - COMPLETED SUCCESSFULLY")
            logging.info("=" * 70)
            
        except Exception as e:
            logging.error(f"Application error: {e}")
            raise


# ============================================================================
# MAIN EXECUTION
# ============================================================================

def main():
    """Main entry point."""
    # Setup logging
    setup_logging()
    
    # Display configuration
    logging.info("Configuration:")
    logging.info(f"  - Extracted files: {CONFIG['extracted_files_path']}")
    logging.info(f"  - Target Excel: {CONFIG['target_excel_path']}")
    logging.info(f"  - Container column: {CONFIG['container_column']}")
    logging.info(f"  - Output report: {CONFIG['output_report']}")
    logging.info("")
    
    # Create and run application
    app = CMRValidationApp(config=CONFIG)
    app.run()


if __name__ == "__main__":
    main()
