{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of the data:\n",
      "  DestinationWarehouse Factory Related transaction company  \\\n",
      "0      Rotterdam- KNNL      东台               JA Solar GmbH   \n",
      "1      Rotterdam- KNNL      东台               JA Solar GmbH   \n",
      "2      Rotterdam- KNNL      东台               JA Solar GmbH   \n",
      "3      Rotterdam- KNNL      东台               JA Solar GmbH   \n",
      "4        Rotterdam- WD      合肥               JA Solar GmbH   \n",
      "\n",
      "  Related transaction Term        EXW        ETD        ETA update ETA ATA  \\\n",
      "0                      CIF 2025-05-22 2025-05-27 2025-07-11        NaT NaT   \n",
      "1                      CIF 2025-05-22 2025-05-27 2025-07-11        NaT NaT   \n",
      "2                      CIF 2025-05-22 2025-05-27 2025-07-11        NaT NaT   \n",
      "3                      CIF 2025-05-22 2025-05-27 2025-07-11        NaT NaT   \n",
      "4                      CIF 2025-05-22 2025-05-25 2025-07-01        NaT NaT   \n",
      "\n",
      "  Date inbound  ...           Type.2 Auxiliary column 成品料号 是否为5.0组件技术(间隙贴膜)  \\\n",
      "0          NaT  ...  JAM66D45-620/LB            D45LB  NaN              NaN   \n",
      "1          NaT  ...  JAM66D45-620/LB            D45LB  NaN              NaN   \n",
      "2          NaT  ...  JAM66D45-620/LB            D45LB  NaN              NaN   \n",
      "3          NaT  ...  JAM66D45-620/LB            D45LB  NaN              NaN   \n",
      "4          NaT  ...  JAM66D46-710/LB            D46LB  NaN              NaN   \n",
      "\n",
      "  Inv&type 是否签收   型号 Unnamed: 67 Unnamed: 68  Unnamed: 69  \n",
      "0      NaN  NaN  NaN         NaN         NaN          NaN  \n",
      "1      NaN  NaN  NaN         NaN         NaN          NaN  \n",
      "2      NaN  NaN  NaN         NaN         NaN          NaN  \n",
      "3      NaN  NaN  NaN         NaN         NaN          NaN  \n",
      "4      NaN  NaN  NaN         NaN         NaN          NaN  \n",
      "\n",
      "[5 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "#Let connect to the database and print the data from this folder \n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "file_path = r\"C:\\Users\\DeepakSureshNidagund\\OneDrive - JA Solar GmbH\\Documents - Sales Dashboards (BI Solution)\\Y_EU Report\\Europe Stock 最新版.xlsx\"\n",
    "    \n",
    "try:\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(file_path):\n",
    "         raise FileNotFoundError(f\"Excel file not found at: {file_path}\")\n",
    "        \n",
    "    # Read the Excel file\n",
    "    df = pd.read_excel(file_path, sheet_name=\"Summary-Europe\")\n",
    "        \n",
    "    # Print the first few rows of the data\n",
    "    print(\"\\nFirst 5 rows of the data:\")\n",
    "    print(df.head())\n",
    "        \n",
    "except Exception as e:\n",
    " print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DestinationWarehouse', 'Factory', 'Related transaction company',\n",
       "       'Related transaction Term', 'EXW', 'ETD', 'ETA', 'update ETA', 'ATA',\n",
       "       'Date inbound', 'inbound status', 'B/L', 'Vessel', 'Sold Date', 'DN',\n",
       "       'Inv.', 'Type', 'Type.1', 'Container', 'Qty(PC)', 'Qty(plts)',\n",
       "       'Power(W)', 'Power(w/pc)', 'Status', 'Customer', 'Salesman',\n",
       "       'Region info', 'Delivery Terms', 'InternalSalesContract',\n",
       "       'External sales contract', 'Currency', 'Inv No.', 'C2 --> C1 Date',\n",
       "       'Handover Date', 'Contractual Delivery Week', 'Country Code', '状态',\n",
       "       'Internal related price', 'Battery type', 'Border Color',\n",
       "       'Junction box', 'length', 'Voltage', '边框信息', 'Storage duration',\n",
       "       'Sold（Week）', 'Storage duration（days）', 'original WH',\n",
       "       'Warehouse after transfer', 'ITS', 'ITS-Remark', 'Identify Risk stock',\n",
       "       'ERP NO', 'ETD month', 'Sold month', 'outbound quantity',\n",
       "       'Rest quantity', 'Released on the sea', 'Booking No.', 'EWX Week',\n",
       "       'Type.2', 'Auxiliary column', '成品料号', '是否为5.0组件技术(间隙贴膜)', 'Inv&type',\n",
       "       '是否签收', '型号', 'Unnamed: 67', 'Unnamed: 68', 'Unnamed: 69'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DestinationWarehouse', 'EXW', 'ETD', 'ETA', 'update ETA', 'ATA',\n",
       "       'Date inbound', 'inbound status', 'B/L', 'Vessel', 'Sold Date',\n",
       "       'Release Number', 'Invoice Number', 'Type', 'Type.1',\n",
       "       'Container Number', 'Qty(PC)', 'Qty(plts)', 'Power(W)', 'Power(w/pc)',\n",
       "       'Status', 'Customer', 'Salesman', 'Region info', 'Delivery Terms',\n",
       "       'InternalSalesContract', 'External sales contract', '边框信息', 'ITS',\n",
       "       'ITS-Remark', 'Identify Risk stock', 'ERP NO', '是否为5.0组件技术(间隙贴膜)',\n",
       "       'Ref1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 1. Remove special characters from specified columns\n",
    "import re\n",
    "def remove_special_chars(val):\n",
    "    if pd.isnull(val):\n",
    "        return val\n",
    "    # Remove special characters and then strip leading/trailing spaces\n",
    "    return re.sub(r'[^A-Za-z0-9 ]+', '', str(val)).strip()\n",
    "\n",
    "columns_to_clean = ['Container', 'DN', 'Inv.']\n",
    "\n",
    "for col in columns_to_clean:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(remove_special_chars)\n",
    "\n",
    "# 2. Rename the columns\n",
    "df = df.rename(columns={\n",
    "    'Inv.': 'Invoice Number',\n",
    "    'Container': 'Container Number',\n",
    "    'DN': 'Release Number'\n",
    "})\n",
    "\n",
    "# 3. Remove specified columns\n",
    "columns_to_remove = [\n",
    "    'Factory', 'Related transaction company', 'Related transaction Term', 'Currency', 'Inv No.', 'C2 --> C1 Date',\n",
    "    'Handover Date', 'Contractual Delivery Week', 'Country Code', '状态', 'Internal related price', 'Battery type',\n",
    "    'Border Color', 'Junction box', 'length', 'Voltage', 'Storage duration', 'Sold（Week）', 'Storage duration（days）',\n",
    "    'original WH', 'Warehouse after transfer', 'ETD month', 'Sold month', 'outbound quantity', 'Rest quantity','是否为5.0组件技术(间隙贴膜)'\n",
    "    'Released on the sea', 'Booking No.', 'EWX Week', 'Type.2', 'Auxiliary column', '成品料号', 'Inv&type', '是否签收',\n",
    "    '型号', 'Unnamed: 65', 'Unnamed: 66', 'Unnamed: 67','Unnamed: 68', 'Unnamed: 69'\n",
    "]\n",
    "\n",
    "# Drop the specified columns\n",
    "df = df.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n",
    "# Create a new column 'Ref1' as concatenation of 'Release Number' and 'Container Number'\n",
    "if 'Release Number' in df.columns and 'Container Number' in df.columns:\n",
    "    df['Ref1'] = df['Release Number'].astype(str) + df['Container Number'].astype(str)\n",
    "else:\n",
    "    df['Ref1'] = None\n",
    "\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into two datasets based on 'Release Number' and 'Not Released'\n",
    "Released_data = df[(df['Release Number'].notna() & (df['Release Number'].astype(str).str.strip() != \"\")) & \n",
    "         (df['Sold Date'].notna() & (df['Sold Date'].astype(str).str.strip() != \"\"))]\n",
    "\n",
    "\n",
    "Not_Released_data = df[(df['Release Number'].isna() | (df['Release Number'].astype(str).str.strip() == \"\")) & \n",
    "         (df['Sold Date'].isna() | (df['Sold Date'].astype(str).str.strip() == \"\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using latest report: CDR_2025-05-22.csv\n",
      "Full path: C:\\Users\\DeepakSureshNidagund\\OneDrive - JA Solar GmbH\\Logistics Reporting\\000_Master_Query_Reports\\Automation_DB\\CDR_Reports\\CDR_2025-05-22.csv\n",
      "\n",
      "First 3 rows of the data:\n",
      "  DestinationWarehouse        EXW        ETD        ETA update ETA ATA  \\\n",
      "0      Rotterdam- KNNL 2025-05-22 2025-05-27 2025-07-11        NaT NaT   \n",
      "1      Rotterdam- KNNL 2025-05-22 2025-05-27 2025-07-11        NaT NaT   \n",
      "2      Rotterdam- KNNL 2025-05-22 2025-05-27 2025-07-11        NaT NaT   \n",
      "\n",
      "  Date inbound inbound status              B/L           Vessel  ...  \\\n",
      "0          NaT            NaN  177SNGNGN89779A  HMM SOUTHAMPTON  ...   \n",
      "1          NaT            NaN  177SNGNGN89779A  HMM SOUTHAMPTON  ...   \n",
      "2          NaT            NaN  177SNGNGN89779A  HMM SOUTHAMPTON  ...   \n",
      "\n",
      "  Delivery Terms InternalSalesContract External sales contract 边框信息  ITS  \\\n",
      "0            NaN    JADX-JAG250405703M                     NaN  NaN  NaN   \n",
      "1            NaN    JADX-JAG250405703M                     NaN  NaN  NaN   \n",
      "2            NaN    JADX-JAG250405703M                     NaN  NaN  NaN   \n",
      "\n",
      "  ITS-Remark  Identify Risk stock      ERP NO  是否为5.0组件技术(间隙贴膜)  \\\n",
      "0        NaN          all regular  3830802207               NaN   \n",
      "1        NaN          all regular  3830802207               NaN   \n",
      "2        NaN          all regular  3830802207               NaN   \n",
      "\n",
      "             Ref1  \n",
      "0  nanFDCU0058487  \n",
      "1  nanMSCU5424266  \n",
      "2  nanMEDU9420753  \n",
      "\n",
      "[3 rows x 34 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DeepakSureshNidagund\\AppData\\Local\\Temp\\ipykernel_2636\\3892510382.py:49: DtypeWarning: Columns (12,23,27,28,29,30,31,34,35,36,62,63,64,65,66,67,69,70) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cdr = pd.read_csv(latest_file)\n"
     ]
    }
   ],
   "source": [
    "# Get the latest CDR report\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Directory path\n",
    "reports_dir = r\"C:\\Users\\DeepakSureshNidagund\\OneDrive - JA Solar GmbH\\Logistics Reporting\\000_Master_Query_Reports\\Automation_DB\\CDR_Reports\"\n",
    "\n",
    "# Check if directory exists\n",
    "if not os.path.exists(reports_dir):\n",
    "    print(f\"Directory does not exist: {reports_dir}\")\n",
    "    print(\"Creating directory...\")\n",
    "    os.makedirs(reports_dir, exist_ok=True)\n",
    "\n",
    "# Try different patterns to find CDR reports\n",
    "patterns = [\n",
    "    \"CDR_*.csv\",  # Primary pattern\n",
    "    \"*CDR*.csv\",  # Secondary pattern - any file with CDR in the name\n",
    "    \"*.csv\"       # Fallback pattern - any CSV file\n",
    "]\n",
    "\n",
    "report_files = []\n",
    "for pattern in patterns:\n",
    "    full_pattern = os.path.join(reports_dir, pattern)\n",
    "    found_files = glob.glob(full_pattern)\n",
    "    if found_files:\n",
    "        report_files = found_files\n",
    "        break\n",
    "\n",
    "if not report_files:\n",
    "    print(f\"No CSV files found in {reports_dir}\")\n",
    "else:\n",
    "    try:\n",
    "        # Try to get the latest file based on date in filename\n",
    "        latest_file = max(report_files, key=lambda x: \n",
    "                        datetime.datetime.strptime(os.path.basename(x).split('_')[1].split('.')[0], \n",
    "                                                \"%Y-%m-%d\"))\n",
    "    except (IndexError, ValueError):\n",
    "        print(\"Could not parse dates from filenames, using file modification time instead.\")\n",
    "        latest_file = max(report_files, key=os.path.getmtime)\n",
    "\n",
    "    print(f\"\\nUsing latest report: {os.path.basename(latest_file)}\")\n",
    "    print(f\"Full path: {latest_file}\")\n",
    "\n",
    "    try:\n",
    "        # Read the CSV file and print first 3 rows\n",
    "        cdr = pd.read_csv(latest_file)\n",
    "        print(\"\\nFirst 3 rows of the data:\")\n",
    "        print(df.head(3))\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {latest_file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now Combinr the 'Released_data' with CDR data to remove the Outbound data from the Released_data based on Ref1\n",
    "\n",
    "cdr_columns = [\"Ref1\", \"Current_Status\", \"Outbound date\", \"Agreed Delivery date\", \"Delivery date\", \"Delivery_Status\"]\n",
    "cdr_selected = cdr[cdr_columns]\n",
    "\n",
    "# Merge the main dataframe with CDR data using Ref1 as the key\n",
    "rno = pd.merge(\n",
    "    Released_data,\n",
    "    cdr_selected,\n",
    "    on=\"Ref1\",\n",
    "    how=\"left\"  # Using left join to keep all records from main df\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DestinationWarehouse', 'EXW', 'ETD', 'ETA', 'update ETA', 'ATA',\n",
      "       'Date inbound', 'inbound status', 'B/L', 'Vessel', 'Sold Date',\n",
      "       'Release Number', 'Invoice Number', 'Type', 'Type.1',\n",
      "       'Container Number', 'Qty(PC)', 'Qty(plts)', 'Power(W)', 'Power(w/pc)',\n",
      "       'Status', 'Customer', 'Salesman', 'Region info', 'Delivery Terms',\n",
      "       'InternalSalesContract', 'External sales contract', '边框信息', 'ITS',\n",
      "       'ITS-Remark', 'Identify Risk stock', 'ERP NO', '是否为5.0组件技术(间隙贴膜)',\n",
      "       'Ref1', 'Current_Status', 'Outbound date', 'Agreed Delivery date',\n",
      "       'Delivery date', 'Delivery_Status'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(rno.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the Outbound Pcs from CDR again with summarization by Ref1 and add a new column called Outbound_Pcs_CDR\n",
    "cdr['Piece'] = pd.to_numeric(cdr['Piece'], errors='coerce')\n",
    "\n",
    "# Create separate summaries for each status\n",
    "on_sea_summary = cdr[cdr['Current_Status'] == 'On Sea'].groupby('Ref1')['Piece'].sum().reset_index()\n",
    "on_sea_summary = on_sea_summary.rename(columns={'Piece': 'On_Sea_Pcs'})\n",
    "\n",
    "in_stock_summary = cdr[cdr['Current_Status'] == 'In-Stock'].groupby('Ref1')['Piece'].sum().reset_index()\n",
    "in_stock_summary = in_stock_summary.rename(columns={'Piece': 'In_Stock_Pcs'})\n",
    "\n",
    "outbounded_summary = cdr[cdr['Current_Status'] == 'Outbounded'].groupby('Ref1')['Piece'].sum().reset_index()\n",
    "outbounded_summary = outbounded_summary.rename(columns={'Piece': 'Outbounded_Pcs'})\n",
    "\n",
    "# Merge all summaries with the main dataframe\n",
    "rno = pd.merge(\n",
    "    rno,\n",
    "    on_sea_summary,\n",
    "    on=\"Ref1\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "rno = pd.merge(\n",
    "    rno,\n",
    "    in_stock_summary,\n",
    "    on=\"Ref1\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "rno = pd.merge(\n",
    "    rno,\n",
    "    outbounded_summary,\n",
    "    on=\"Ref1\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Fill NaN values with 0 for all new columns\n",
    "rno['On_Sea_Pcs'] = rno['On_Sea_Pcs'].fillna(0)\n",
    "rno['In_Stock_Pcs'] = rno['In_Stock_Pcs'].fillna(0)\n",
    "rno['Outbounded_Pcs'] = rno['Outbounded_Pcs'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column, Outbound_Pcs_CDR compare which is Outbound_Pcs = Qty(PC) in rno report\n",
    "rno['Qty(PC)'] = pd.to_numeric(rno['Qty(PC)'], errors='coerce')\n",
    "rno['Outbounded_Pcs'] = pd.to_numeric(rno['Outbounded_Pcs'], errors='coerce')\n",
    "\n",
    "# Create comparison column based on Current_Status\n",
    "import numpy as np\n",
    "rno['Outbound_Comparison'] = np.where(\n",
    "    rno['Current_Status'] == 'Outbounded',\n",
    "    rno['Outbounded_Pcs'] - rno['Qty(PC)'],\n",
    "    rno['Qty(PC)']\n",
    ")\n",
    "\n",
    "#replace the neqtive value of 'Outbound_Comparison' with  rno['Qty(PC)']\n",
    "rno['Outbound_Comparison'] = np.where(\n",
    "    rno['Outbound_Comparison'] < 0,\n",
    "    rno['Qty(PC)'],\n",
    "    rno['Outbound_Comparison']\n",
    ")\n",
    "\n",
    "# Add a new column as Case1 which is ['Outbound_Comparison'] == ['Qty(PC)'] as True and False\n",
    "rno['Case1'] = np.where(\n",
    "    rno['Outbound_Comparison'] == rno['Qty(PC)'],\n",
    "    True,\n",
    "    False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found latest WMS report: Combined_Outbound_WMS_20250522.xlsx\n",
      "Full path: C:\\Users\\DeepakSureshNidagund\\OneDrive - JA Solar GmbH\\Documents - Sales Dashboards (BI Solution)\\a_Combinded WM_Report\\Outbound_WMS_Report\\Combined_Outbound_WMS_20250522.xlsx\n",
      "Last modified: 2025-05-22 19:16:57.520339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully loaded data with 23954 rows and 26 columns\n",
      "Index(['Base name', 'Organization Code', 'Organization Name', 'Warehouse',\n",
      "       'Wharea', 'Wharea Name', 'Wharea.1', 'Internal invoice number',\n",
      "       'Container number', 'Release number', 'Type', 'Quantity', 'Wattage',\n",
      "       'Total wattage', 'Trade terms', 'Operation Time', 'statisticsDate',\n",
      "       'Outbound time', 'Signing time', 'External contract number',\n",
      "       'Delivery Address', 'Country Code', 'Number of Pallets',\n",
      "       'carbonFootprint', 'Source_File', 'Ref1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Get data from WMS Report\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "#Define the directory path for WMS reports\n",
    "wms_dir = r\"C:\\Users\\DeepakSureshNidagund\\OneDrive - JA Solar GmbH\\Documents - Sales Dashboards (BI Solution)\\a_Combinded WM_Report\\Outbound_WMS_Report\"\n",
    "\n",
    "# Check if directory exists\n",
    "if not os.path.exists(wms_dir):\n",
    "    print(f\"Error: Directory does not exist: {wms_dir}\")\n",
    "    exit(1)\n",
    "\n",
    "# Find all Excel files in the directory\n",
    "excel_files = glob.glob(os.path.join(wms_dir, \"*.xlsx\"))\n",
    "\n",
    "# Check if any files were found\n",
    "if not excel_files:\n",
    "    print(f\"No Excel files found in {wms_dir}\")\n",
    "    exit(1)\n",
    "\n",
    "# Get the latest file based on modification time\n",
    "latest_file = max(excel_files, key=os.path.getmtime)\n",
    "\n",
    "print(f\"Found latest WMS report: {os.path.basename(latest_file)}\")\n",
    "print(f\"Full path: {latest_file}\")\n",
    "print(f\"Last modified: {datetime.fromtimestamp(os.path.getmtime(latest_file))}\")\n",
    "\n",
    "try:\n",
    "    # Read the Excel file\n",
    "    wms_Outbound = pd.read_excel(latest_file)\n",
    "    print(f\"\\nSuccessfully loaded data with {len( wms_Outbound)} rows and {len( wms_Outbound.columns)} columns\")\n",
    "    \n",
    "    \n",
    "    print( wms_Outbound.columns)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error reading file {latest_file}: {e}\") \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create Ref1 column as concatenation of Release Number and Container Number\n",
    "# if 'Release number' in wms_Outbound.columns and 'Container number' in wms_Outbound.columns:\n",
    "#     wms_Outbound['Ref1'] = wms_Outbound['Release number'].astype(str) + wms_Outbound['Container number'].astype(str)\n",
    "# else:\n",
    "#     wms_Outbound['Ref1'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on Ref1 from rno and Ref1 from wms_Outbound, get the total 'Quantity' from wms_Outbound and add it to rno as a new column called 'Outbound_Pcs_WMS'\n",
    "wms_summary = wms_Outbound.groupby('Ref1')['Quantity'].sum().reset_index()\n",
    "wms_summary = wms_summary.rename(columns={'Quantity': 'Pcs_from_wms'})\n",
    "\n",
    "# Merge the summary with rno DataFrame\n",
    "rno = pd.merge(\n",
    "    rno,\n",
    "    wms_summary,\n",
    "    on='Ref1',\n",
    "    how='left'  # Use left join to keep all records from rno\n",
    ")\n",
    "\n",
    "\n",
    "# Fill any NaN values with 0 for the new column\n",
    "rno['Pcs_from_wms'] = rno['Pcs_from_wms'].fillna(0)\n",
    "\n",
    "# Convert to numeric to ensure proper data type\n",
    "rno['Pcs_from_wms'] = pd.to_numeric(rno['Pcs_from_wms'], errors='coerce')\n",
    "\n",
    "# Add a new column as Case2 which is rno['Pcs_from_wms'] == rno['Outbounded_Pcs'] as True and False\n",
    "rno['Case2'] = np.where(\n",
    "    rno['Pcs_from_wms'] == rno['Outbounded_Pcs'],\n",
    "    True,\n",
    "    False\n",
    ")\n",
    "\n",
    "\n",
    "# Add a new column as Case3 which is ['Outbound_Comparison'] == ['Qty(PC)'] as True and False\n",
    "rno['Case3'] = np.where(\n",
    "    rno['Pcs_from_wms'] == rno['Qty(PC)'] ,\n",
    "    True,\n",
    "    False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get two summaries from CDR:\n",
    "# 1. Total pieces by container\n",
    "# 2. Outbounded pieces by container\n",
    "cdr_total_summary = cdr.groupby('Container No.')['Piece'].sum().reset_index()\n",
    "cdr_outbound_summary = cdr[cdr['Current_Status'] == 'Outbounded'].groupby('Container No.')['Piece'].sum().reset_index()\n",
    "\n",
    "# Rename columns to be descriptive\n",
    "cdr_total_summary = cdr_total_summary.rename(columns={'Piece': 'cnt_Total_Pcs_cdr'})\n",
    "cdr_outbound_summary = cdr_outbound_summary.rename(columns={'Piece': 'cnt_Outbound_Pcs_cdr'})\n",
    "\n",
    "# Merge both summaries with rno DataFrame\n",
    "rno = pd.merge(\n",
    "    rno,\n",
    "    cdr_total_summary,\n",
    "    left_on='Container Number',\n",
    "    right_on='Container No.',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "rno = pd.merge(\n",
    "    rno,\n",
    "    cdr_outbound_summary,\n",
    "    left_on='Container Number',\n",
    "    right_on='Container No.',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN values with 0 for both new columns\n",
    "rno['cnt_Total_Pcs_cdr'] = rno['cnt_Total_Pcs_cdr'].fillna(0)\n",
    "rno['cnt_Outbound_Pcs_cdr'] = rno['cnt_Outbound_Pcs_cdr'].fillna(0)\n",
    "\n",
    "# Convert to numeric to ensure proper data type\n",
    "rno['cnt_Total_Pcs_cdr'] = pd.to_numeric(rno['cnt_Total_Pcs_cdr'], errors='coerce')\n",
    "rno['cnt_Outbound_Pcs_cdr'] = pd.to_numeric(rno['cnt_Outbound_Pcs_cdr'], errors='coerce')\n",
    "\n",
    "# Clean up by dropping the extra 'Container No.' columns that were added during merges\n",
    "rno = rno.drop(['Container No._x', 'Container No._y'], axis=1, errors='ignore')\n",
    "\n",
    "rno['Case4'] = np.where(\n",
    "    rno['cnt_Outbound_Pcs_cdr'] == rno['Qty(PC)'],\n",
    "    True,\n",
    "    False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Add the filters one by one to row the filters\n",
    "\n",
    "# Now filter out rows that meet all the specified conditions where Currecnt status = Outbounded  & In stock = 0  & Case_2 = True (cdr pcs = wms pcs only outbound )\n",
    "rno = rno[~((rno['Current_Status'] == 'Outbounded') & \n",
    "            (rno['In_Stock_Pcs'] == 0) & \n",
    "            (rno['Case2'] == True))]\n",
    "\n",
    "\n",
    "# Now filter out rows that meet all the specified conditions where Currecnt status = Outbounded  & In stock = 0  & Case_3 = True (wms pcs = wms pcs only outbound )\n",
    "rno = rno[~((rno['Current_Status'] == 'Outbounded') & \n",
    "            (rno['In_Stock_Pcs'] == 0) & \n",
    "            (rno['Case3'] == True))]\n",
    "\n",
    "\n",
    "\n",
    "# Now filter out rows that meet all the specified conditions where Currecnt status = Outbounded  & In stock = 0  & Case_4 = True (cdr pcs = rno pcs at cotainer lvl pcs only outbound )\n",
    "rno = rno[~((rno['Current_Status'] == 'Outbounded') & \n",
    "            (rno['In_Stock_Pcs'] == 0) & \n",
    "            (rno['Case4'] == True))]\n",
    "\n",
    "# Remove the row where the Current status == Outbounded and Outbound_Comparison ==0\n",
    "rno = rno[\n",
    "    ~((rno['Current_Status'] == 'Outbounded') & \n",
    "      (rno['Outbound_Comparison'] == 0))\n",
    "]\n",
    "\n",
    "\n",
    "# Now remove the row where the Current status == Outbounded and Case_2 == TRUE\n",
    "rno = rno[\n",
    "    ~((rno['Current_Status'] == 'Outbounded') & \n",
    "      (rno['Case2'] == True))\n",
    "]\n",
    "\n",
    "# Remove the rows Current status == Outbounded\n",
    "rno = rno[\n",
    "    ~((rno['Current_Status'] == 'Outbounded'))]\n",
    "\n",
    "\n",
    "# Remove rows where Container Number is null/blank\n",
    "rno = rno[rno['Container Number'].notna() & (rno['Container Number'].str.strip() != '')]\n",
    "\n",
    "\n",
    "# Read the Remove_data file\n",
    "remove_data_path = r\"C:\\Users\\DeepakSureshNidagund\\Downloads\\Reporting Application\\Automation\\automation\\tests\\Remove_data.xlsx\"\n",
    "remove_df = pd.read_excel(remove_data_path)\n",
    "ref1_to_remove = remove_df['Ref1'].tolist()\n",
    "rno = rno[~rno['Ref1'].isin(ref1_to_remove)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rno.to_csv(\"rno_report.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################           Remove the Rows cases               ############################################\n",
    "# Filter/Remove the row which the Current_Status is Outbounded and Delivery_Status is Full_delivery\n",
    "rno = rno[\n",
    "    ~((rno['Current_Status'] == 'Outbound') | \n",
    "      (rno['Delivery_Status'] == 'Full_delivery'))\n",
    "]\n",
    "\n",
    "\n",
    "# Remove the rows where the Outbound_Comparison is 0\n",
    "rno = rno[rno['Outbound_Comparison'] != 0]\n",
    "\n",
    "\n",
    "# Now filter out rows that meet all the specified conditions\n",
    "\n",
    "rno = rno[~((rno['Current_Status'] == 'Outbounded') & \n",
    "            (rno['In_Stock_Pcs'] == 0) & \n",
    "            (rno['Case2'] == True))]\n",
    "\n",
    "\n",
    "# Now filter out rows that meet all the specified conditions\n",
    "rno = rno[~((rno['Current_Status'] == 'Outbounded') & \n",
    "            (rno['In_Stock_Pcs'] == 0) & \n",
    "            (rno['Case2'] == False)&\n",
    "            (rno['Case3'] == True))]\n",
    "\n",
    "\n",
    "# Now filter out rows that meet all the specified conditions outboud pcs in Wms  equal to cnt outbond pcs in cdr \n",
    "rno = rno[~((rno['Case3'] == True) & \n",
    "            (rno['Case4'] == True))]\n",
    "\n",
    "\n",
    "# Read the Remove_data file\n",
    "remove_data_path = r\"C:\\Users\\DeepakSureshNidagund\\Downloads\\Reporting Application\\Automation\\automation\\tests\\Remove_data.xlsx\"\n",
    "remove_df = pd.read_excel(remove_data_path)\n",
    "\n",
    "# Get the list of Ref1 values to remove\n",
    "ref1_to_remove = remove_df['Ref1'].tolist()\n",
    "\n",
    "# Remove rows from rno where Ref1 matches any value in ref1_to_remove\n",
    "rno = rno[~rno['Ref1'].isin(ref1_to_remove)]\n",
    "\n",
    "\n",
    "#Remove all the case of outbounded from this rno \n",
    "rno = rno[~((rno['Current_Status'] == 'Outbounded'))]\n",
    "\n",
    "\n",
    "# Remove duplicates based on Ref1 column, keeping the first occurrence\n",
    "rno = rno.drop_duplicates(subset=['Ref1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Base name', 'Organization Code', 'Organization Name', 'Warehouse',\n",
      "       'Wharea', 'Wharea Name', 'Wharea.1', 'Internal invoice number',\n",
      "       'Container number', 'Release number', 'Type', 'Quantity', 'Wattage',\n",
      "       'Total wattage', 'Trade terms', 'Operation Time', 'statisticsDate',\n",
      "       'Outbound time', 'Signing time', 'External contract number',\n",
      "       'Delivery Address', 'Country Code', 'Number of Pallets',\n",
      "       'carbonFootprint', 'Source_File', 'Ref1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print( wms_Outbound.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Name JA partner', 'WH location', 'Type of WH (bonded/non)',\n",
       "       'Container No.', 'Product type', 'Product reference', 'Port of Loading',\n",
       "       'Port of destination', 'Inbound ref.', 'Import invoice', 'House B/l',\n",
       "       'Bill of Lading', 'Shipping line', 'Vessel', 'ETD date POL',\n",
       "       'ATD date POL', 'ETA date', 'ATA date', 'Import MRN', 'Import date',\n",
       "       'Planned Inbound date', 'Inbound date',\n",
       "       'Inbound duration days (Inbound date-ATA date+1)', 'Inbound Status',\n",
       "       'Dev. Planned to Real in days (Inbound date-Planned inbound date',\n",
       "       'Release date from port (ATA date)',\n",
       "       'Contractual freetime for D&D combined', 'Free DM days', 'Free DT days',\n",
       "       'Free DM days remained', 'Free DT days remained',\n",
       "       'Container Returned date', 'Factory JASolar', 'Pallets', 'Piece',\n",
       "       'Wattage', 'Stock Status', 'Stock age', 'Release Number',\n",
       "       'Release type', 'Incoterm', 'Release date', 'Internal Outbound ref',\n",
       "       'Outbound date', 'Outbound Status', 'Agreed Delivery date',\n",
       "       'Delivery date', 'Storage time after release', 'Delivery Duration',\n",
       "       'Dev. Between Agreed vs Real delivery date', 'Sales Name',\n",
       "       'date CMR sent to JASolar', 'Customer Name', 'Customer Country',\n",
       "       'Consignee name', 'Destination Address', 'Destination Postal Code',\n",
       "       'Destination City', 'Destination Country', 'Sales invoice',\n",
       "       'PTW / intermodel type', 'Port fees (THC, ISPS, etc. )', 'DM cost',\n",
       "       'DT cost', 'Port storage cost', 'Drayage costs (Port to WH)',\n",
       "       'Inbound costs', 'Storage costs (fm IB to Today/OB)', 'Outbound costs',\n",
       "       'Transport costs', 'Comments', 'created_at', 'Power', 'MegaWattage',\n",
       "       'Ref1', 'Ref2', 'Status', 'Current_Status', 'Outbound_status',\n",
       "       'Release_Status', 'Delivery_Status', 'data_source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Released_data.to_csv(\"Released_data.csv\", index=False)\n",
    "Not_Released_data.to_csv(\"Not_Released_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
