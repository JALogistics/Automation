{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DeepakSureshNidagund\\AppData\\Roaming\\Python\\Python313\\site-packages\\openpyxl\\worksheet\\_reader.py:223: UserWarning: Cell O23886 is marked as a date but the serial value 2407090024 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of the data:\n",
      "  DestinationWarehouse Factory Related transaction company  \\\n",
      "0      Rotterdam- KNNL      东台               JA Solar GmbH   \n",
      "1        Koper- Glovis      奉贤               JA Solar GmbH   \n",
      "2        Koper- Glovis      奉贤               JA Solar GmbH   \n",
      "3        Koper- Glovis      奉贤               JA Solar GmbH   \n",
      "4        Koper- Glovis      奉贤               JA Solar GmbH   \n",
      "\n",
      "  Related transaction Term                  EXW                  ETD  \\\n",
      "0                      CIF  2024-05-12 00:00:00                  NaN   \n",
      "1                      CIF  2025-05-20 00:00:00  2025-05-24 00:00:00   \n",
      "2                      CIF  2025-05-20 00:00:00  2025-05-24 00:00:00   \n",
      "3                      CIF  2025-05-20 00:00:00  2025-05-24 00:00:00   \n",
      "4                      CIF  2025-05-20 00:00:00  2025-05-23 00:00:00   \n",
      "\n",
      "                   ETA update ETA ATA         Date inbound  ...  EWX Week  \\\n",
      "0                  NaN        NaT NaT  2024-07-09 00:00:00  ...  2024年05月   \n",
      "1  2025-06-30 00:00:00        NaT NaT                  NaN  ...  2025年05月   \n",
      "2  2025-06-30 00:00:00        NaT NaT                  NaN  ...  2025年05月   \n",
      "3  2025-06-30 00:00:00        NaT NaT                  NaN  ...  2025年05月   \n",
      "4  2025-07-07 00:00:00        NaT NaT                  NaN  ...  2025年05月   \n",
      "\n",
      "            Type.2 Auxiliary column 成品料号 Inv&type 是否签收   型号 Unnamed: 65  \\\n",
      "0  JAM72D40-585/MB            D40MB  NaN      NaN  NaN  NaN         NaN   \n",
      "1  JAM60D40-500/LB            D40LB  NaN      NaN  NaN  NaN         NaN   \n",
      "2  JAM60D40-500/LB            D40LB  NaN      NaN  NaN  NaN         NaN   \n",
      "3  JAM60D40-500/LB            D40LB  NaN      NaN  NaN  NaN         NaN   \n",
      "4  JAM54D40-450/LB            D40LB  NaN      NaN  NaN  NaN         NaN   \n",
      "\n",
      "  Unnamed: 66  Unnamed: 67  \n",
      "0         NaN          NaN  \n",
      "1         NaN          NaN  \n",
      "2         NaN          NaN  \n",
      "3         NaN          NaN  \n",
      "4         NaN          NaN  \n",
      "\n",
      "[5 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "#Let connect to the database and print the data from this folder \n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "file_path = r\"C:\\Users\\DeepakSureshNidagund\\OneDrive - JA Solar GmbH\\Documents - Sales Dashboards (BI Solution)\\Y_EU Report\\Europe Stock 最新版.xlsx\"\n",
    "    \n",
    "try:\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(file_path):\n",
    "         raise FileNotFoundError(f\"Excel file not found at: {file_path}\")\n",
    "        \n",
    "    # Read the Excel file\n",
    "    df = pd.read_excel(file_path, sheet_name=\"Summary-Europe\")\n",
    "        \n",
    "    # Print the first few rows of the data\n",
    "    print(\"\\nFirst 5 rows of the data:\")\n",
    "    print(df.head())\n",
    "        \n",
    "except Exception as e:\n",
    " print(f\"An error occurred: {e}\")\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DestinationWarehouse', 'Factory', 'Related transaction company',\n",
       "       'Related transaction Term', 'EXW', 'ETD', 'ETA', 'update ETA', 'ATA',\n",
       "       'Date inbound', 'inbound status', 'B/L', 'Vessel', 'Sold Date', 'DN',\n",
       "       'Inv.', 'Type', 'Type.1', 'Container', 'Qty(PC)', 'Qty(plts)',\n",
       "       'Power(W)', 'Power(w/pc)', 'Status', 'Customer', 'Salesman',\n",
       "       'Region info', 'Delivery Terms', 'InternalSalesContract',\n",
       "       'External sales contract', 'Currency', 'Inv No.', 'C2 --> C1 Date',\n",
       "       'Handover Date', 'Contractual Delivery Week', 'Country Code', '状态',\n",
       "       'Internal related price', 'Battery type', 'Border Color',\n",
       "       'Junction box', 'length', 'Voltage', 'Storage duration', 'Sold（Week）',\n",
       "       'Storage duration（days）', 'original WH', 'Warehouse after transfer',\n",
       "       'ITS', 'ITS-Remark', 'Identify Risk stock', 'ERP NO', 'ETD month',\n",
       "       'Sold month', 'outbound quantity', 'Rest quantity',\n",
       "       'Released on the sea', 'Booking No.', 'EWX Week', 'Type.2',\n",
       "       'Auxiliary column', '成品料号', 'Inv&type', '是否签收', '型号', 'Unnamed: 65',\n",
       "       'Unnamed: 66', 'Unnamed: 67'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DestinationWarehouse', 'EXW', 'ETD', 'ETA', 'update ETA', 'ATA',\n",
       "       'Date inbound', 'inbound status', 'B/L', 'Vessel', 'Sold Date',\n",
       "       'Release Number', 'Invoice Number', 'Type', 'Type.1',\n",
       "       'Container Number', 'Qty(PC)', 'Qty(plts)', 'Power(W)', 'Power(w/pc)',\n",
       "       'Status', 'Customer', 'Salesman', 'Region info', 'Delivery Terms',\n",
       "       'InternalSalesContract', 'External sales contract', 'ITS', 'ITS-Remark',\n",
       "       'Identify Risk stock', 'ERP NO', 'Ref1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 1. Remove special characters from specified columns\n",
    "import re\n",
    "def remove_special_chars(val):\n",
    "    if pd.isnull(val):\n",
    "        return val\n",
    "    # Remove special characters and then strip leading/trailing spaces\n",
    "    return re.sub(r'[^A-Za-z0-9 ]+', '', str(val)).strip()\n",
    "\n",
    "columns_to_clean = ['Container', 'DN', 'Inv.']\n",
    "\n",
    "for col in columns_to_clean:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(remove_special_chars)\n",
    "\n",
    "# 2. Rename the columns\n",
    "df = df.rename(columns={\n",
    "    'Inv.': 'Invoice Number',\n",
    "    'Container': 'Container Number',\n",
    "    'DN': 'Release Number'\n",
    "})\n",
    "\n",
    "# 3. Remove specified columns\n",
    "columns_to_remove = [\n",
    "    'Factory', 'Related transaction company', 'Related transaction Term', 'Currency', 'Inv No.', 'C2 --> C1 Date',\n",
    "    'Handover Date', 'Contractual Delivery Week', 'Country Code', '状态', 'Internal related price', 'Battery type',\n",
    "    'Border Color', 'Junction box', 'length', 'Voltage', 'Storage duration', 'Sold（Week）', 'Storage duration（days）',\n",
    "    'original WH', 'Warehouse after transfer', 'ETD month', 'Sold month', 'outbound quantity', 'Rest quantity',\n",
    "    'Released on the sea', 'Booking No.', 'EWX Week', 'Type.2', 'Auxiliary column', '成品料号', 'Inv&type', '是否签收',\n",
    "    '型号', 'Unnamed: 65', 'Unnamed: 66', 'Unnamed: 67'\n",
    "]\n",
    "\n",
    "# Drop the specified columns\n",
    "df = df.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n",
    "# Create a new column 'Ref1' as concatenation of 'Release Number' and 'Container Number'\n",
    "if 'Release Number' in df.columns and 'Container Number' in df.columns:\n",
    "    df['Ref1'] = df['Release Number'].astype(str) + df['Container Number'].astype(str)\n",
    "else:\n",
    "    df['Ref1'] = None\n",
    "\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into two datasets based on 'Release Number' and 'Not Released'\n",
    "Released_data = df[(df['Release Number'].notna() & (df['Release Number'].astype(str).str.strip() != \"\")) & \n",
    "         (df['Sold Date'].notna() & (df['Sold Date'].astype(str).str.strip() != \"\"))]\n",
    "\n",
    "\n",
    "Not_Released_data = df[(df['Release Number'].isna() | (df['Release Number'].astype(str).str.strip() == \"\")) & \n",
    "         (df['Sold Date'].isna() | (df['Sold Date'].astype(str).str.strip() == \"\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using latest report: CDR_2025-05-20.csv\n",
      "Full path: C:\\Users\\DeepakSureshNidagund\\OneDrive - JA Solar GmbH\\Logistics Reporting\\000_Master_Query_Reports\\Automation_DB\\CDR_Reports\\CDR_2025-05-20.csv\n",
      "\n",
      "First 3 rows of the data:\n",
      "  DestinationWarehouse                  EXW                  ETD  \\\n",
      "0      Rotterdam- KNNL  2024-05-12 00:00:00                  NaN   \n",
      "1        Koper- Glovis  2025-05-20 00:00:00  2025-05-24 00:00:00   \n",
      "2        Koper- Glovis  2025-05-20 00:00:00  2025-05-24 00:00:00   \n",
      "\n",
      "                   ETA update ETA ATA         Date inbound  \\\n",
      "0                  NaN        NaT NaT  2024-07-09 00:00:00   \n",
      "1  2025-06-30 00:00:00        NaT NaT                  NaN   \n",
      "2  2025-06-30 00:00:00        NaT NaT                  NaN   \n",
      "\n",
      "        inbound status               B/L                 Vessel  ... Salesman  \\\n",
      "0  in bonded warehouse  EGLV142452996115    EVER ARIA 1296-007W  ...    Eurus   \n",
      "1                  NaN        CHN2275849  CMA CGM ADONIS 0BEKZW  ...   Celine   \n",
      "2                  NaN        CHN2275849  CMA CGM ADONIS 0BEKZW  ...   Celine   \n",
      "\n",
      "                        Region info Delivery Terms InternalSalesContract  \\\n",
      "0  North and Central Eastern Europe            FCA    JADX-JAG240408267M   \n",
      "1              UK and Mediterranean            NaN     JAF-JAG250402620M   \n",
      "2              UK and Mediterranean            NaN     JAF-JAG250402620M   \n",
      "\n",
      "  External sales contract  ITS  ITS-Remark  Identify Risk stock      ERP NO  \\\n",
      "0      JAG-RASS241103001M  NaN         NaN            low power  3830800731   \n",
      "1                     NaN  NaN         NaN          all regular  6105004236   \n",
      "2                     NaN  NaN         NaN          all regular  6105004236   \n",
      "\n",
      "                    Ref1  \n",
      "0  2411180005TXGU7394882  \n",
      "1         nanCMAU4941555  \n",
      "2         nanTLLU7873163  \n",
      "\n",
      "[3 rows x 32 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DeepakSureshNidagund\\AppData\\Local\\Temp\\ipykernel_15792\\3892510382.py:49: DtypeWarning: Columns (12,23,27,28,29,30,31,34,35,36,62,63,64,65,66,67,69,70) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cdr = pd.read_csv(latest_file)\n"
     ]
    }
   ],
   "source": [
    "# Get the latest CDR report\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Directory path\n",
    "reports_dir = r\"C:\\Users\\DeepakSureshNidagund\\OneDrive - JA Solar GmbH\\Logistics Reporting\\000_Master_Query_Reports\\Automation_DB\\CDR_Reports\"\n",
    "\n",
    "# Check if directory exists\n",
    "if not os.path.exists(reports_dir):\n",
    "    print(f\"Directory does not exist: {reports_dir}\")\n",
    "    print(\"Creating directory...\")\n",
    "    os.makedirs(reports_dir, exist_ok=True)\n",
    "\n",
    "# Try different patterns to find CDR reports\n",
    "patterns = [\n",
    "    \"CDR_*.csv\",  # Primary pattern\n",
    "    \"*CDR*.csv\",  # Secondary pattern - any file with CDR in the name\n",
    "    \"*.csv\"       # Fallback pattern - any CSV file\n",
    "]\n",
    "\n",
    "report_files = []\n",
    "for pattern in patterns:\n",
    "    full_pattern = os.path.join(reports_dir, pattern)\n",
    "    found_files = glob.glob(full_pattern)\n",
    "    if found_files:\n",
    "        report_files = found_files\n",
    "        break\n",
    "\n",
    "if not report_files:\n",
    "    print(f\"No CSV files found in {reports_dir}\")\n",
    "else:\n",
    "    try:\n",
    "        # Try to get the latest file based on date in filename\n",
    "        latest_file = max(report_files, key=lambda x: \n",
    "                        datetime.datetime.strptime(os.path.basename(x).split('_')[1].split('.')[0], \n",
    "                                                \"%Y-%m-%d\"))\n",
    "    except (IndexError, ValueError):\n",
    "        print(\"Could not parse dates from filenames, using file modification time instead.\")\n",
    "        latest_file = max(report_files, key=os.path.getmtime)\n",
    "\n",
    "    print(f\"\\nUsing latest report: {os.path.basename(latest_file)}\")\n",
    "    print(f\"Full path: {latest_file}\")\n",
    "\n",
    "    try:\n",
    "        # Read the CSV file and print first 3 rows\n",
    "        cdr = pd.read_csv(latest_file)\n",
    "        print(\"\\nFirst 3 rows of the data:\")\n",
    "        print(df.head(3))\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {latest_file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now Combinr the 'Released_data' with CDR data to remove the Outbound data from the Released_data based on Ref1\n",
    "\n",
    "cdr_columns = [\"Ref1\", \"Current_Status\", \"Outbound date\", \"Agreed Delivery date\", \"Delivery date\", \"Delivery_Status\"]\n",
    "cdr_selected = cdr[cdr_columns]\n",
    "\n",
    "# Merge the main dataframe with CDR data using Ref1 as the key\n",
    "rno = pd.merge(\n",
    "    Released_data,\n",
    "    cdr_selected,\n",
    "    on=\"Ref1\",\n",
    "    how=\"left\"  # Using left join to keep all records from main df\n",
    ")\n",
    "\n",
    "# Filter/Remove the row which the Current_Status is Outbounded and Delivery_Status is Full_delivery\n",
    "rno = rno[\n",
    "    ~((rno['Current_Status'] == 'Outbound') | \n",
    "      (rno['Delivery_Status'] == 'Full_delivery'))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DestinationWarehouse', 'EXW', 'ETD', 'ETA', 'update ETA', 'ATA',\n",
      "       'Date inbound', 'inbound status', 'B/L', 'Vessel', 'Sold Date',\n",
      "       'Release Number', 'Invoice Number', 'Type', 'Type.1',\n",
      "       'Container Number', 'Qty(PC)', 'Qty(plts)', 'Power(W)', 'Power(w/pc)',\n",
      "       'Status', 'Customer', 'Salesman', 'Region info', 'Delivery Terms',\n",
      "       'InternalSalesContract', 'External sales contract', 'ITS', 'ITS-Remark',\n",
      "       'Identify Risk stock', 'ERP NO', 'Ref1', 'Current_Status',\n",
      "       'Outbound date', 'Agreed Delivery date', 'Delivery date',\n",
      "       'Delivery_Status'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(rno.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the Outbound Pcs from CDR again with summarization by Ref1 and add a new column called Outbound_Pcs_CDR\n",
    "cdr['Piece'] = pd.to_numeric(cdr['Piece'], errors='coerce')\n",
    "\n",
    "# Create separate summaries for each status\n",
    "on_sea_summary = cdr[cdr['Current_Status'] == 'On Sea'].groupby('Ref1')['Piece'].sum().reset_index()\n",
    "on_sea_summary = on_sea_summary.rename(columns={'Piece': 'On_Sea_Pcs'})\n",
    "\n",
    "in_stock_summary = cdr[cdr['Current_Status'] == 'In-Stock'].groupby('Ref1')['Piece'].sum().reset_index()\n",
    "in_stock_summary = in_stock_summary.rename(columns={'Piece': 'In_Stock_Pcs'})\n",
    "\n",
    "outbounded_summary = cdr[cdr['Current_Status'] == 'Outbounded'].groupby('Ref1')['Piece'].sum().reset_index()\n",
    "outbounded_summary = outbounded_summary.rename(columns={'Piece': 'Outbounded_Pcs'})\n",
    "\n",
    "# Merge all summaries with the main dataframe\n",
    "rno = pd.merge(\n",
    "    rno,\n",
    "    on_sea_summary,\n",
    "    on=\"Ref1\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "rno = pd.merge(\n",
    "    rno,\n",
    "    in_stock_summary,\n",
    "    on=\"Ref1\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "rno = pd.merge(\n",
    "    rno,\n",
    "    outbounded_summary,\n",
    "    on=\"Ref1\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Fill NaN values with 0 for all new columns\n",
    "rno['On_Sea_Pcs'] = rno['On_Sea_Pcs'].fillna(0)\n",
    "rno['In_Stock_Pcs'] = rno['In_Stock_Pcs'].fillna(0)\n",
    "rno['Outbounded_Pcs'] = rno['Outbounded_Pcs'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column, Outbound_Pcs_CDR compare which is Outbound_Pcs = Qty(PC) in rno report\n",
    "rno['Qty(PC)'] = pd.to_numeric(rno['Qty(PC)'], errors='coerce')\n",
    "rno['Outbounded_Pcs'] = pd.to_numeric(rno['Outbounded_Pcs'], errors='coerce')\n",
    "\n",
    "# Create comparison column based on Current_Status\n",
    "import numpy as np\n",
    "rno['Outbound_Comparison'] = np.where(\n",
    "    rno['Current_Status'] == 'Outbounded',\n",
    "    rno['Outbounded_Pcs'] - rno['Qty(PC)'],\n",
    "    rno['Qty(PC)']\n",
    ")\n",
    "\n",
    "# Remove the rows where the Outbound_Comparison is 0\n",
    "rno = rno[rno['Outbound_Comparison'] != 0]\n",
    "\n",
    "\n",
    "#replace the neqtive value of 'Outbound_Comparison' with  rno['Qty(PC)']\n",
    "rno['Outbound_Comparison'] = np.where(\n",
    "    rno['Outbound_Comparison'] < 0,\n",
    "    rno['Qty(PC)'],\n",
    "    rno['Outbound_Comparison']\n",
    ")\n",
    "\n",
    "# Add a new column as Case1 which is ['Outbound_Comparison'] == ['Qty(PC)'] as True and False\n",
    "rno['Case1'] = np.where(\n",
    "    rno['Outbound_Comparison'] == rno['Qty(PC)'],\n",
    "    True,\n",
    "    False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found latest WMS report: Combined_Outbound_WMS_20250521.xlsx\n",
      "Full path: C:\\Users\\DeepakSureshNidagund\\OneDrive - JA Solar GmbH\\Documents - Sales Dashboards (BI Solution)\\a_Combinded WM_Report\\Outbound_WMS_Report\\Combined_Outbound_WMS_20250521.xlsx\n",
      "Last modified: 2025-05-21 15:11:14\n",
      "\n",
      "Successfully loaded data with 23954 rows and 25 columns\n",
      "Index(['Base name', 'Organization Code', 'Organization Name', 'Warehouse',\n",
      "       'Wharea', 'Wharea Name', 'Wharea.1', 'Internal invoice number',\n",
      "       'Container number', 'Release number', 'Type', 'Quantity', 'Wattage',\n",
      "       'Total wattage', 'Trade terms', 'Operation Time', 'statisticsDate',\n",
      "       'Outbound time', 'Signing time', 'External contract number',\n",
      "       'Delivery Address', 'Country Code', 'Number of Pallets',\n",
      "       'carbonFootprint', 'Source_File'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Get data from WMS Report\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "#Define the directory path for WMS reports\n",
    "wms_dir = r\"C:\\Users\\DeepakSureshNidagund\\OneDrive - JA Solar GmbH\\Documents - Sales Dashboards (BI Solution)\\a_Combinded WM_Report\\Outbound_WMS_Report\"\n",
    "\n",
    "# Check if directory exists\n",
    "if not os.path.exists(wms_dir):\n",
    "    print(f\"Error: Directory does not exist: {wms_dir}\")\n",
    "    exit(1)\n",
    "\n",
    "# Find all Excel files in the directory\n",
    "excel_files = glob.glob(os.path.join(wms_dir, \"*.xlsx\"))\n",
    "\n",
    "# Check if any files were found\n",
    "if not excel_files:\n",
    "    print(f\"No Excel files found in {wms_dir}\")\n",
    "    exit(1)\n",
    "\n",
    "# Get the latest file based on modification time\n",
    "latest_file = max(excel_files, key=os.path.getmtime)\n",
    "\n",
    "print(f\"Found latest WMS report: {os.path.basename(latest_file)}\")\n",
    "print(f\"Full path: {latest_file}\")\n",
    "print(f\"Last modified: {datetime.fromtimestamp(os.path.getmtime(latest_file))}\")\n",
    "\n",
    "try:\n",
    "    # Read the Excel file\n",
    "    wms_Outbound = pd.read_excel(latest_file)\n",
    "    print(f\"\\nSuccessfully loaded data with {len( wms_Outbound)} rows and {len( wms_Outbound.columns)} columns\")\n",
    "    \n",
    "    \n",
    "    print( wms_Outbound.columns)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error reading file {latest_file}: {e}\") \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Ref1 column as concatenation of Release Number and Container Number\n",
    "if 'Release number' in wms_Outbound.columns and 'Container number' in wms_Outbound.columns:\n",
    "    wms_Outbound['Ref1'] = wms_Outbound['Release number'].astype(str) + wms_Outbound['Container number'].astype(str)\n",
    "else:\n",
    "    wms_Outbound['Ref1'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on Ref1 from rno and Ref1 from wms_Outbound, get the total 'Quantity' from wms_Outbound and add it to rno as a new column called 'Outbound_Pcs_WMS'\n",
    "wms_summary = wms_Outbound.groupby('Ref1')['Quantity'].sum().reset_index()\n",
    "wms_summary = wms_summary.rename(columns={'Quantity': 'Pcs_from_wms'})\n",
    "\n",
    "# Merge the summary with rno DataFrame\n",
    "rno = pd.merge(\n",
    "    rno,\n",
    "    wms_summary,\n",
    "    on='Ref1',\n",
    "    how='left'  # Use left join to keep all records from rno\n",
    ")\n",
    "\n",
    "# Fill any NaN values with 0 for the new column\n",
    "rno['Pcs_from_wms'] = rno['Pcs_from_wms'].fillna(0)\n",
    "\n",
    "# Convert to numeric to ensure proper data type\n",
    "rno['Pcs_from_wms'] = pd.to_numeric(rno['Pcs_from_wms'], errors='coerce')\n",
    "\n",
    "# Add a new column as Case2 which is rno['Pcs_from_wms'] == rno['Outbounded_Pcs'] as True and False\n",
    "rno['Case2'] = np.where(\n",
    "    rno['Pcs_from_wms'] == rno['Outbounded_Pcs'],\n",
    "    True,\n",
    "    False\n",
    ")\n",
    "\n",
    "\n",
    "# Add a new column as Case3 which is ['Outbound_Comparison'] == ['Qty(PC)'] as True and False\n",
    "rno['Case3'] = np.where(\n",
    "    rno['Pcs_from_wms'] == rno['Qty(PC)'] ,\n",
    "    True,\n",
    "    False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now filter out rows that meet all the specified conditions\n",
    "rno = rno[~((rno['Current_Status'] == 'Outbounded') & \n",
    "            (rno['In_Stock_Pcs'] == 0) & \n",
    "            (rno['Case2'] == True))]\n",
    "\n",
    "\n",
    "# Now filter out rows that meet all the specified conditions\n",
    "rno = rno[~((rno['Current_Status'] == 'Outbounded') & \n",
    "            (rno['In_Stock_Pcs'] == 0) & \n",
    "            (rno['Case2'] == False)&\n",
    "            (rno['Case3'] == True))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get two summaries from CDR:\n",
    "# 1. Total pieces by container\n",
    "# 2. Outbounded pieces by container\n",
    "cdr_total_summary = cdr.groupby('Container No.')['Piece'].sum().reset_index()\n",
    "cdr_outbound_summary = cdr[cdr['Current_Status'] == 'Outbounded'].groupby('Container No.')['Piece'].sum().reset_index()\n",
    "\n",
    "# Rename columns to be descriptive\n",
    "cdr_total_summary = cdr_total_summary.rename(columns={'Piece': 'cnt_Total_Pcs_cdr'})\n",
    "cdr_outbound_summary = cdr_outbound_summary.rename(columns={'Piece': 'cnt_Outbound_Pcs_cdr'})\n",
    "\n",
    "# Merge both summaries with rno DataFrame\n",
    "rno = pd.merge(\n",
    "    rno,\n",
    "    cdr_total_summary,\n",
    "    left_on='Container Number',\n",
    "    right_on='Container No.',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "rno = pd.merge(\n",
    "    rno,\n",
    "    cdr_outbound_summary,\n",
    "    left_on='Container Number',\n",
    "    right_on='Container No.',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN values with 0 for both new columns\n",
    "rno['cnt_Total_Pcs_cdr'] = rno['cnt_Total_Pcs_cdr'].fillna(0)\n",
    "rno['cnt_Outbound_Pcs_cdr'] = rno['cnt_Outbound_Pcs_cdr'].fillna(0)\n",
    "\n",
    "# Convert to numeric to ensure proper data type\n",
    "rno['cnt_Total_Pcs_cdr'] = pd.to_numeric(rno['cnt_Total_Pcs_cdr'], errors='coerce')\n",
    "rno['cnt_Outbound_Pcs_cdr'] = pd.to_numeric(rno['cnt_Outbound_Pcs_cdr'], errors='coerce')\n",
    "\n",
    "# Clean up by dropping the extra 'Container No.' columns that were added during merges\n",
    "rno = rno.drop(['Container No._x', 'Container No._y'], axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rno.to_csv(\"rno_report.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Base name', 'Organization Code', 'Organization Name', 'Warehouse',\n",
      "       'Wharea', 'Wharea Name', 'Wharea.1', 'Internal invoice number',\n",
      "       'Container number', 'Release number', 'Type', 'Quantity', 'Wattage',\n",
      "       'Total wattage', 'Trade terms', 'Operation Time', 'statisticsDate',\n",
      "       'Outbound time', 'Signing time', 'External contract number',\n",
      "       'Delivery Address', 'Country Code', 'Number of Pallets',\n",
      "       'carbonFootprint', 'Source_File', 'Ref1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print( wms_Outbound.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Name JA partner', 'WH location', 'Type of WH (bonded/non)',\n",
       "       'Container No.', 'Product type', 'Product reference', 'Port of Loading',\n",
       "       'Port of destination', 'Inbound ref.', 'Import invoice', 'House B/l',\n",
       "       'Bill of Lading', 'Shipping line', 'Vessel', 'ETD date POL',\n",
       "       'ATD date POL', 'ETA date', 'ATA date', 'Import MRN', 'Import date',\n",
       "       'Planned Inbound date', 'Inbound date',\n",
       "       'Inbound duration days (Inbound date-ATA date+1)', 'Inbound Status',\n",
       "       'Dev. Planned to Real in days (Inbound date-Planned inbound date',\n",
       "       'Release date from port (ATA date)',\n",
       "       'Contractual freetime for D&D combined', 'Free DM days', 'Free DT days',\n",
       "       'Free DM days remained', 'Free DT days remained',\n",
       "       'Container Returned date', 'Factory JASolar', 'Pallets', 'Piece',\n",
       "       'Wattage', 'Stock Status', 'Stock age', 'Release Number',\n",
       "       'Release type', 'Incoterm', 'Release date', 'Internal Outbound ref',\n",
       "       'Outbound date', 'Outbound Status', 'Agreed Delivery date',\n",
       "       'Delivery date', 'Storage time after release', 'Delivery Duration',\n",
       "       'Dev. Between Agreed vs Real delivery date', 'Sales Name',\n",
       "       'date CMR sent to JASolar', 'Customer Name', 'Customer Country',\n",
       "       'Consignee name', 'Destination Address', 'Destination Postal Code',\n",
       "       'Destination City', 'Destination Country', 'Sales invoice',\n",
       "       'PTW / intermodel type', 'Port fees (THC, ISPS, etc. )', 'DM cost',\n",
       "       'DT cost', 'Port storage cost', 'Drayage costs (Port to WH)',\n",
       "       'Inbound costs', 'Storage costs (fm IB to Today/OB)', 'Outbound costs',\n",
       "       'Transport costs', 'Comments', 'created_at', 'Power', 'MegaWattage',\n",
       "       'Ref1', 'Ref2', 'Status', 'Current_Status', 'Outbound_status',\n",
       "       'Release_Status', 'Delivery_Status', 'data_source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Released_data.to_csv(\"Released_data.csv\", index=False)\n",
    "Not_Released_data.to_csv(\"Not_Released_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
